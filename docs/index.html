<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>nsc 0.1.0 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="#" class="icon icon-home"> nsc
          </a>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-readme">Neural spell checking using Transformers and Graph Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-models">Pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-reproduce">Training and reproducing results</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-nsc">nsc package</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">nsc</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="#" class="icon icon-home"></a> &raquo;</li>
      <li>nsc 0.1.0 documentation</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="toctree-wrapper compound">
<span id="document-readme"></span><section id="neural-spell-checking-using-transformers-and-graph-neural-networks">
<h1>Neural spell checking using Transformers and Graph Neural Networks<a class="headerlink" href="#neural-spell-checking-using-transformers-and-graph-neural-networks" title="Permalink to this headline"></a></h1>
<p>This project is about detecting and correcting spelling errors using Transformers and
Graph Neural Networks. Visit the <a class="reference external" href="https://bastiscode.github.io/spell_check">documentation</a> (which also includes this README)
for more information on how to reproduce results and train your own models.</p>
<section id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this headline"></a></h2>
<p>Clone the repository</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git clone git@github.com:bastiscode/spell_check.git
</pre></div>
</div>
<p>Install from source (alternatively you can use <a class="reference internal" href="#docker">Docker</a>)</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>make install
</pre></div>
</div>
</section>
<section id="usage">
<h2>Usage<a class="headerlink" href="#usage" title="Permalink to this headline"></a></h2>
<p>There are two main ways to use this project.
Either via the command line or by directly using the Python API.</p>
<section id="command-line-interfaces">
<h3>Command line interfaces<a class="headerlink" href="#command-line-interfaces" title="Permalink to this headline"></a></h3>
<p>After installation there will be three commands available in your environment:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">nsec</span></code> for neural spelling error correction</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">nsed</span></code> for neural spelling error detection</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ntr</span></code> for neural tokenization repair</p></li>
</ol>
<p>By default all three commands take input from <cite>stdin</cite>, run their respective task on the
input line by line and print their output line by line to <cite>stdout</cite>. Let’s look at some
basic examples on how to use the command line tools.</p>
<p><strong>Spelling error correction using</strong> <code class="docutils literal notranslate"><span class="pre">nsec</span></code></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># correct text by piping into nsec,</span>
<span class="nb">echo</span> <span class="s2">&quot;This is an incorect sentense!&quot;</span> <span class="p">|</span> nsec
cat path/to/file.txt <span class="p">|</span> nsec

<span class="c1"># by using the -c flag,</span>
nsec -c <span class="s2">&quot;This is an incorect sentense!&quot;</span>

<span class="c1"># by passing a file,</span>
nsec -f path/to/file.txt

<span class="c1"># or by starting an interactive session</span>
nsec -i

<span class="c1"># you can also use spelling correction to detect errors on word and sequence level</span>
nsec -c <span class="s2">&quot;This is an incorect sentense!&quot;</span> --convert-output word_detections
nsec -c <span class="s2">&quot;This is an incorect sentense!&quot;</span> --convert-output sequence_detections
</pre></div>
</div>
<p><strong>Spelling error detection using</strong> <code class="docutils literal notranslate"><span class="pre">nsed</span></code></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># detect errors by piping into nsed,</span>
<span class="nb">echo</span> <span class="s2">&quot;This is an incorect sentense!&quot;</span> <span class="p">|</span> nsed
cat path/to/file.txt <span class="p">|</span> nsed

<span class="c1"># by using the -d flag,</span>
nsed -d <span class="s2">&quot;This is an incorect sentense!&quot;</span>

<span class="c1"># by passing a file,</span>
nsed -f path/to/file.txt

<span class="c1"># or by starting an interactive session</span>
nsed -i

<span class="c1"># you can also use word level spelling error detections to detect sequence level errors</span>
nsed -d <span class="s2">&quot;This is an incorect sentense!&quot;</span> --convert-sequence
</pre></div>
</div>
<p><strong>Tokenization repair using</strong> <code class="docutils literal notranslate"><span class="pre">ntr</span></code></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># repair text by piping into ntr,</span>
<span class="nb">echo</span> <span class="s2">&quot;Thisis an inc orect sentens e!&quot;</span> <span class="p">|</span> ntr
cat path/to/file.txt <span class="p">|</span> ntr

<span class="c1"># by using the -r flag,</span>
ntr -r <span class="s2">&quot;Thisis an inc orect sentens e!&quot;</span>

<span class="c1"># by passing a file,</span>
ntr -f path/to/file.txt

<span class="c1"># or by starting an interactive session</span>
ntr -i
</pre></div>
</div>
<p>You can also combine the <code class="docutils literal notranslate"><span class="pre">ntr</span></code>, <code class="docutils literal notranslate"><span class="pre">nsed</span></code>, and <code class="docutils literal notranslate"><span class="pre">nsec</span></code> commands in a variety of ways.
Some examples are shown below.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># repair and detect</span>
<span class="nb">echo</span> <span class="s2">&quot;Repi arand core ct tihs sen tens!&quot;</span> <span class="p">|</span> ntr <span class="p">|</span> nsed
<span class="c1"># to view both the repaired text and the detections use</span>
<span class="nb">echo</span> <span class="s2">&quot;Repi arand core ct tihs sen tens!&quot;</span> <span class="p">|</span> ntr <span class="p">|</span> nsed --sec-out

<span class="c1"># repair and correct</span>
<span class="nb">echo</span> <span class="s2">&quot;Repi arand core ct tihs sen tens!&quot;</span> <span class="p">|</span> ntr <span class="p">|</span> nsec

<span class="c1"># repair and correct a file and save the output</span>
ntr -f path/to/file.txt <span class="p">|</span> nsec --progress -o path/to/output_file.txt

<span class="c1"># repair, detect and correct</span>
<span class="c1"># (this pipeline uses the spelling error detection output</span>
<span class="c1"># to guide the spelling error correction model to correct only the misspelled words)</span>
<span class="nb">echo</span> <span class="s2">&quot;Repi arand core ct tihs sen tens!&quot;</span> <span class="p">|</span> ntr <span class="p">|</span> nsed --sec-out <span class="p">|</span> nsec --sed-in

<span class="c1"># some detection and correction models (e.g. tokenization repair+, tokenization repair++, transformer with tokenization repair nmt)</span>
<span class="c1"># can natively deal with incorrect whitespacing in text, so there is no need to use ntr before them if you want to process</span>
<span class="c1"># text with whitespacing errors</span>
nsed -d <span class="s2">&quot;core ct thissen tense!&quot;</span> -m <span class="s2">&quot;sed words:tokenization repair+&quot;</span> --sec-out
nsec -c <span class="s2">&quot;core ct thissen tense!&quot;</span> -m <span class="s2">&quot;tokenization repair++&quot;</span>
nsec -c <span class="s2">&quot;core ct thissen tense!&quot;</span> -m <span class="s2">&quot;transformer with tokenization repair nmt&quot;</span>
</pre></div>
</div>
<p>There are a few other command line options available for the <code class="docutils literal notranslate"><span class="pre">nsec</span></code>, <code class="docutils literal notranslate"><span class="pre">nsed</span></code> and <code class="docutils literal notranslate"><span class="pre">ntr</span></code> commands. Inspect
them by passing the <code class="docutils literal notranslate"><span class="pre">-h</span> <span class="pre">/</span> <span class="pre">--help</span></code> flag to the commands.</p>
</section>
<section id="python-api">
<h3>Python API<a class="headerlink" href="#python-api" title="Permalink to this headline"></a></h3>
<p>We also provide a Python API for you to use spell checking models directly in code. Below are basic
code examples on how to use the API. For the full documentation of all classes, methods, etc. provided by
the Python API see the <a class="reference external" href="#module-nsc">nsc package documentation</a>.</p>
<p><strong>Spelling error correction</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nsc</span> <span class="kn">import</span> <span class="n">SpellingErrorCorrector</span><span class="p">,</span> <span class="n">get_available_spelling_error_correction_models</span>

<span class="c1"># show all spelling error correction models</span>
<span class="nb">print</span><span class="p">(</span><span class="n">get_available_spelling_error_correction_models</span><span class="p">())</span>

<span class="c1"># use a pretrained model</span>
<span class="n">sec</span> <span class="o">=</span> <span class="n">SpellingErrorCorrector</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">()</span>
<span class="c1"># correct errors in text</span>
<span class="n">correction</span> <span class="o">=</span> <span class="n">sec</span><span class="o">.</span><span class="n">correct_text</span><span class="p">(</span><span class="s2">&quot;Tihs text has erors!&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">correction</span><span class="p">)</span>
<span class="c1"># correct errors in file</span>
<span class="n">corrections</span> <span class="o">=</span> <span class="n">sec</span><span class="o">.</span><span class="n">correct_file</span><span class="p">(</span><span class="s2">&quot;path/to/file.txt&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">correction</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Spelling error detection</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nsc</span> <span class="kn">import</span> <span class="n">SpellingErrorDetector</span><span class="p">,</span> <span class="n">get_available_spelling_error_detection_models</span>

<span class="c1"># show all spelling error detection models</span>
<span class="nb">print</span><span class="p">(</span><span class="n">get_available_spelling_error_detection_models</span><span class="p">())</span>

<span class="c1"># use a pretrained model</span>
<span class="n">sed</span> <span class="o">=</span> <span class="n">SpellingErrorDetector</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">()</span>
<span class="c1"># detect errors in text</span>
<span class="n">detection</span> <span class="o">=</span> <span class="n">sed</span><span class="o">.</span><span class="n">detect_text</span><span class="p">(</span><span class="s2">&quot;Tihs text has erors!&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">detection</span><span class="p">)</span>
<span class="c1"># detect errors in file</span>
<span class="n">detections</span> <span class="o">=</span> <span class="n">sed</span><span class="o">.</span><span class="n">detect_file</span><span class="p">(</span><span class="s2">&quot;path/to/file.txt&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">detections</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Tokenization repair</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nsc</span> <span class="kn">import</span> <span class="n">TokenizationRepairer</span><span class="p">,</span> <span class="n">get_available_tokenization_repair_models</span>

<span class="c1"># show all tokenization repair models</span>
<span class="nb">print</span><span class="p">(</span><span class="n">get_available_tokenization_repair_models</span><span class="p">())</span>

<span class="c1"># use a pretrained model</span>
<span class="n">tr</span> <span class="o">=</span> <span class="n">TokenizationRepairer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">()</span>
<span class="c1"># repair tokenization in text</span>
<span class="n">repaired_text</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">repair_text</span><span class="p">(</span><span class="s2">&quot;Ti hstext h aserors!&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">repaired_text</span><span class="p">)</span>
<span class="c1"># repair tokenization in file</span>
<span class="n">repaired_file</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">repair_file</span><span class="p">(</span><span class="s2">&quot;path/to/file.txt&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">repaired_file</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="docker">
<h2>Docker<a class="headerlink" href="#docker" title="Permalink to this headline"></a></h2>
<p>This project can also be run using Docker.
Inside the Docker container both the <a class="reference internal" href="#command-line-interfaces">Command line interfaces</a> and <a class="reference internal" href="#python-api">Python API</a> are available for you to use.
You can also evaluate model predictions on benchmarks.</p>
<p>Build the Docker image:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>make build_docker
</pre></div>
</div>
<p>Start a Docker container:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># run the docker container with GPU support</span>
make run_docker_gpu
<span class="c1"># or with CPU support only</span>
make run_docker_cpu
</pre></div>
</div>
<p>You can also pass additional Docker arguments to the make commands by specifying <code class="docutils literal notranslate"><span class="pre">DOCKER_ARGS</span></code>. For example,
to mount an additional directory inside the container use
<code class="docutils literal notranslate"><span class="pre">make</span> <span class="pre">DOCKER_ARGS=&quot;-v</span> <span class="pre">/path/to/outside/directory:/path/to/container/directory&quot;</span> <span class="pre">run_docker_gpu</span></code>.</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>If you build the Docker image on an AD Server you probably want to use wharfer instead of
Docker. To do that call the make commands with the additional argument <code class="docutils literal notranslate"><span class="pre">DOCKER_CMD=wharfer</span></code>,
e.g. <code class="docutils literal notranslate"><span class="pre">make</span> <span class="pre">DOCKER_CMD=wharfer</span> <span class="pre">build_docker</span></code>.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The Docker setup is only intended to be used for running the command line tools/Python API with pretrained or
your own models and evaluating benchmarks, but not for training.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Running the Docker container with GPU support assumes that you have the <a class="reference external" href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html">NVIDIA Container Toolkit</a> installed.</p>
</div>
</section>
</section>
<span id="document-models"></span><section id="pretrained-models">
<h1>Pretrained models<a class="headerlink" href="#pretrained-models" title="Permalink to this headline"></a></h1>
<p>The following table shows all pretrained models available for the CLI tools and Python API:</p>
<table class="docutils align-default" id="id1">
<caption><span class="caption-text">Table</span><a class="headerlink" href="#id1" title="Permalink to this table"></a></caption>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Task (CLI tool/Python class)</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Default</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>tokenization repair (<code class="docutils literal notranslate"><span class="pre">ntr</span></code>/<code class="docutils literal notranslate"><span class="pre">TokenizationRepairer</span></code>)</p></td>
<td><p>eo large arxiv with errors</p></td>
<td><p>Large-sized Transformer model (12 layers) that repairs sequences by predicting repair tokens for each character (ported from <a class="reference external" href="https://github.com/ad-freiburg/trt">https://github.com/ad-freiburg/trt</a>).</p></td>
<td><p>X</p></td>
</tr>
<tr class="row-odd"><td><p>tokenization repair (<code class="docutils literal notranslate"><span class="pre">ntr</span></code>/<code class="docutils literal notranslate"><span class="pre">TokenizationRepairer</span></code>)</p></td>
<td><p>eo medium arxiv with errors</p></td>
<td><p>Medium-sized Transformer model (6 layers) that repairs sequences by predicting repair tokens for each character (ported from <a class="reference external" href="https://github.com/ad-freiburg/trt">https://github.com/ad-freiburg/trt</a>).</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>tokenization repair (<code class="docutils literal notranslate"><span class="pre">ntr</span></code>/<code class="docutils literal notranslate"><span class="pre">TokenizationRepairer</span></code>)</p></td>
<td><p>eo small arxiv with errors</p></td>
<td><p>Small-sized Transformer model (3 layers) that repairs sequences by predicting repair tokens for each character (ported from <a class="reference external" href="https://github.com/ad-freiburg/trt">https://github.com/ad-freiburg/trt</a>).</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>tokenization repair (<code class="docutils literal notranslate"><span class="pre">ntr</span></code>/<code class="docutils literal notranslate"><span class="pre">TokenizationRepairer</span></code>)</p></td>
<td><p>tokenization repair+</p></td>
<td><p>Same as eo medium arxiv with errors, available here for completeness.</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>tokenization repair (<code class="docutils literal notranslate"><span class="pre">ntr</span></code>/<code class="docutils literal notranslate"><span class="pre">TokenizationRepairer</span></code>)</p></td>
<td><p>tokenization repair++</p></td>
<td><p>Same as eo medium arxiv with errors, available here for completeness.</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>sed words (<code class="docutils literal notranslate"><span class="pre">nsed</span></code>/<code class="docutils literal notranslate"><span class="pre">SpellingErrorDetector</span></code>)</p></td>
<td><p>gnn+</p></td>
<td><p>Attentional Graph Neural Network which processes language graphs with fully connected word nodes, word features and fully connected sub-word cliques. Predicts spelling errors on word level using the word node representations.</p></td>
<td><p>X</p></td>
</tr>
<tr class="row-even"><td><p>sed words (<code class="docutils literal notranslate"><span class="pre">nsed</span></code>/<code class="docutils literal notranslate"><span class="pre">SpellingErrorDetector</span></code>)</p></td>
<td><p>gnn+ neuspell</p></td>
<td><p>Attentional Graph Neural Network which processes language graphs with fully connected word nodes, word features and fully connected sub-word cliques. Predicts spelling errors on word level using the word node representations. (pretrained without Neuspell and BEA misspellings, finetuned on Neuspell training data)</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>sed words (<code class="docutils literal notranslate"><span class="pre">nsed</span></code>/<code class="docutils literal notranslate"><span class="pre">SpellingErrorDetector</span></code>)</p></td>
<td><p>transformer</p></td>
<td><p>Regular transformer processing a sequence of sub-word tokens. Predicts spelling errors on word level using the aggregated sub-word representations per word.</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>sed words (<code class="docutils literal notranslate"><span class="pre">nsed</span></code>/<code class="docutils literal notranslate"><span class="pre">SpellingErrorDetector</span></code>)</p></td>
<td><p>transformer neuspell</p></td>
<td><p>Regular transformer processing a sequence of sub-word tokens. Predicts spelling errors on word level using the aggregated sub-word representations per word. (pretrained without Neuspell and BEA misspellings, finetuned on Neuspell training data)</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>sed words (<code class="docutils literal notranslate"><span class="pre">nsed</span></code>/<code class="docutils literal notranslate"><span class="pre">SpellingErrorDetector</span></code>)</p></td>
<td><p>transformer+</p></td>
<td><p>Regular transformer processing a sequence of sub-word tokens. Before predicting spelling errors, sub-word representations within a word are aggregated and enriched with word features to obtain word representations. Predicts spelling errors on word level using those word representations.</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>sed words (<code class="docutils literal notranslate"><span class="pre">nsed</span></code>/<code class="docutils literal notranslate"><span class="pre">SpellingErrorDetector</span></code>)</p></td>
<td><p>transformer+ neuspell</p></td>
<td><p>Regular transformer processing a sequence of sub-word tokens. Before predicting spelling errors, sub-word representations within a word are aggregated and enriched with word features to obtain word representations. Predicts spelling errors on word level using those word representations. (pretrained without Neuspell and BEA misspellings, finetuned on Neuspell training data)</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>sed words (<code class="docutils literal notranslate"><span class="pre">nsed</span></code>/<code class="docutils literal notranslate"><span class="pre">SpellingErrorDetector</span></code>)</p></td>
<td><p>gnn</p></td>
<td><p>Attentional Graph Neural Network which processes language graphs with fully connected word nodes and fully connected sub-word cliques. Predicts spelling errors on word level using the word node representations.</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>sed words (<code class="docutils literal notranslate"><span class="pre">nsed</span></code>/<code class="docutils literal notranslate"><span class="pre">SpellingErrorDetector</span></code>)</p></td>
<td><p>gnn neuspell</p></td>
<td><p>Attentional Graph Neural Network which processes language graphs with fully connected word nodes and fully connected sub-word cliques. Predicts spelling errors on word level using the word node representations. (pretrained without Neuspell and BEA misspellings, finetuned on Neuspell training data)</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>sed words (<code class="docutils literal notranslate"><span class="pre">nsed</span></code>/<code class="docutils literal notranslate"><span class="pre">SpellingErrorDetector</span></code>)</p></td>
<td><p>tokenization repair+</p></td>
<td><p>Transformer based model that detects errors in sequences by first correcting the tokenization and then detecting spelling errors for each word in the repaired text.</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>sed words (<code class="docutils literal notranslate"><span class="pre">nsed</span></code>/<code class="docutils literal notranslate"><span class="pre">SpellingErrorDetector</span></code>)</p></td>
<td><p>tokenization repair++</p></td>
<td><p>Transformer based model that detects errors in sequences by first correcting the tokenization and then detecting spelling errors for each word in the repaired text. Different from tokenization repair+ because this model was trained to also correct spelling errors (it is also available in nsec).</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>sec (<code class="docutils literal notranslate"><span class="pre">nsec</span></code>/<code class="docutils literal notranslate"><span class="pre">SpellingErrorCorrector</span></code>)</p></td>
<td><p>transformer words nmt</p></td>
<td><p>Transformer model that corrects sequences by translating each word individually from misspelled to correct.</p></td>
<td><p>X</p></td>
</tr>
<tr class="row-even"><td><p>sec (<code class="docutils literal notranslate"><span class="pre">nsec</span></code>/<code class="docutils literal notranslate"><span class="pre">SpellingErrorCorrector</span></code>)</p></td>
<td><p>transformer words nmt neuspell</p></td>
<td><p>Transformer model that corrects sequences by translating each word individually from misspelled to correct. (pretrained without Neuspell and BEA misspellings, finetuned on Neuspell training data)</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>sec (<code class="docutils literal notranslate"><span class="pre">nsec</span></code>/<code class="docutils literal notranslate"><span class="pre">SpellingErrorCorrector</span></code>)</p></td>
<td><p>tokenization repair++</p></td>
<td><p>Transformer based model that corrects sequences by first correcting the tokenization, then detecting spelling errors for each word in the repaired text and then translating every detected misspelled word to its corrected version.</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>sec (<code class="docutils literal notranslate"><span class="pre">nsec</span></code>/<code class="docutils literal notranslate"><span class="pre">SpellingErrorCorrector</span></code>)</p></td>
<td><p>transformer nmt</p></td>
<td><p>Transformer model that translates a sequence with spelling errors into a sequence without spelling errors.</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>sec (<code class="docutils literal notranslate"><span class="pre">nsec</span></code>/<code class="docutils literal notranslate"><span class="pre">SpellingErrorCorrector</span></code>)</p></td>
<td><p>transformer nmt neuspell</p></td>
<td><p>Transformer model that translates a sequence with spelling errors into a sequence without spelling errors. (pretrained without Neuspell and BEA misspellings, finetuned on Neuspell training data)</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>sec (<code class="docutils literal notranslate"><span class="pre">nsec</span></code>/<code class="docutils literal notranslate"><span class="pre">SpellingErrorCorrector</span></code>)</p></td>
<td><p>transformer with tokenization repair nmt</p></td>
<td><p>Transformer model that translates a sequence with spelling and tokenization errors into a sequence without spelling and tokenization errors. Different from transformer nmt because this model tokenizes into characters and was trained on text with spelling and tokenization errors, whereas transformer nmt tokenizes into sub-words and was trained only on text with spelling errors.</p></td>
<td></td>
</tr>
</tbody>
</table>
</section>
<span id="document-reproduce"></span><section id="training-and-reproducing-results">
<h1>Training and reproducing results<a class="headerlink" href="#training-and-reproducing-results" title="Permalink to this headline"></a></h1>
<p>You can skip the following training section if you only want to use pretrained models and not
train your own models.</p>
<section id="training">
<h2>Training<a class="headerlink" href="#training" title="Permalink to this headline"></a></h2>
<p>Before starting training you need the get the training data. Everything you need
(preprocessed samples, tokenizer, dictionaries, etc.) can be found under <code class="docutils literal notranslate"><span class="pre">/nfs/students/sebastian-walter/masters_thesis/data</span></code>.</p>
<p>You also need to set the following two special environment variables:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># set the data directory</span>
<span class="nb">export</span> <span class="nv">NSC_DATA_DIR</span><span class="o">=</span>/nfs/students/sebastian-walter/masters_thesis/data

<span class="c1"># set the config directory (necessary to be able to compose</span>
<span class="c1"># the final training config from sub-configs)</span>
<span class="nb">export</span> <span class="nv">NSC_CONFIG_DIR</span><span class="o">=</span>spell_checking/configs
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Of course you can also copy the training data folder to every other
place you like and adjust <code class="docutils literal notranslate"><span class="pre">NSC_DATA_DIR</span></code> accordingly. But keep in mind that this
folder is very large (&gt; 1TB).</p>
</div>
<p>After that you can train your own models using a training config.
All of the training configs this project used to train models can be found <a class="reference external" href="https://github.com/bastiscode/spell_check/tree/main/spell_checking/configs/train">here</a>.</p>
<p>You might have to further configure a training config by setting additional environment variables. Let’s
look at an example where we want to train a spelling error detection Graph Neural Network. The <a class="reference external" href="https://github.com/bastiscode/spell_check/tree/main/spell_checking/configs/train/sed_words.yaml">config
for this task</a> looks like the following:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">variant</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${from_file:variant/sed_words.yaml}</span>
<span class="nt">model</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${from_file:model/model_for_sed_words.yaml}</span>
<span class="nt">optimizer</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${from_file:optimizer/adamw.yaml}</span>
<span class="nt">lr_scheduler</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${from_file:lr_scheduler/step_with_0.05_warmup.yaml}</span>

<span class="nt">experiment_dir</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${oc.env:NSC_EXPERIMENT_DIR}</span>
<span class="nt">data_dir</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${oc.env:NSC_DATA_DIR}</span>
<span class="nt">datasets</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">${oc.env:NSC_DATA_DIR}/processed/wikidump_paragraphs_sed_words_and_sec</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">${oc.env:NSC_DATA_DIR}/processed/bookcorpus_paragraphs_sed_words_and_sec</span>
<span class="nt">dataset_limits</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">${oc.env:NSC_DATA_LIMIT}</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">${oc.env:NSC_DATA_LIMIT}</span>
<span class="nt">val_splits</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">2500</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">2500</span>

<span class="nt">experiment_name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${oc.env:NSC_EXPERIMENT_NAME,dummy}</span>
<span class="nt">epochs</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${oc.env:NSC_EPOCHS,1}</span>
<span class="nt">batch_max_length</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${oc.env:NSC_BATCH_MAX_LENGTH,4096}</span>
<span class="nt">bucket_span</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${oc.env:NSC_BUCKET_SPAN,4}</span>
<span class="nt">log_per_epoch</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${oc.env:NSC_LOG_PER_EPOCH,100}</span>
<span class="nt">eval_per_epoch</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${oc.env:NSC_EVAL_PER_EPOCH,4}</span>
<span class="nt">seed</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">22</span>
<span class="nt">mixed_precision</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${oc.env:NSC_MIXED_PRECISION,true}</span>
</pre></div>
</div>
<p>Values looking like <code class="docutils literal notranslate"><span class="pre">${from_file:&lt;file_path&gt;}</span></code> refer to other config files relative to the <code class="docutils literal notranslate"><span class="pre">NSC_CONFIG_DIR</span></code>. When the training
config is composed, the contents of the referred config files will replace these values.</p>
<p>Values looking like <code class="docutils literal notranslate"><span class="pre">${oc.env:&lt;env_var_name&gt;,&lt;default&gt;}</span></code> refer to environment variables and an optional default that will be set
if the environment variable is not found. If there is no default you will be required to set the environment variable, otherwise
you receive an error message.</p>
<p>In our example we need to set values for the environment variables <code class="docutils literal notranslate"><span class="pre">NSC_DATA_LIMIT</span></code> (can be used to limit the number of samples per training dataset)
and <code class="docutils literal notranslate"><span class="pre">NSC_EXPERIMENT_DIR</span></code> (directory path where the logs and checkpoints will be saved). Once we have set these variables we
can start the training. Since the training script is written to support distributed training we need to use <a class="reference external" href="https://pytorch.org/docs/stable/elastic/run.html">torchrun</a>
to launch the script:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># set the environment variables</span>
<span class="nb">export</span> <span class="nv">NSC_DATA_LIMIT</span><span class="o">=</span><span class="m">100000</span> <span class="c1"># set data limit to 100,000 samples per dataset</span>
<span class="nb">export</span> <span class="nv">NSC_EXPERIMENT_DIR</span><span class="o">=</span>experiments <span class="c1"># directory path where the experiment will be saved</span>

<span class="c1"># to train locally / on a single node</span>
torchrun --nnodes<span class="o">=</span><span class="m">1</span> nsc/train.py --config spell_checking/configs/sed_words.yaml
</pre></div>
</div>
<p>You can also resume training for an existing experiment if you had to abort training for some reason:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># resume training from latest checkpoint of an experiment</span>
torchrun --nnodes<span class="o">=</span><span class="m">1</span> nsc/train.py --resume &lt;path_to_experiment_directory&gt;
</pre></div>
</div>
<p>As an alternative you can set one of the <code class="docutils literal notranslate"><span class="pre">NSC_CONFIG</span></code> or <code class="docutils literal notranslate"><span class="pre">NSC_RESUME</span></code> environment variables
and use the <a class="reference external" href="https://github.com/bastiscode/spell_check/tree/main/spell_checking/scripts/train.sh">train.sh</a> script to start training. This script additionally provides functionality to start distributed
training on <a class="reference external" href="https://slurm.schedmd.com/documentation.html">SLURM</a> clusters. Training using this script would look something like this:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># set the environment variables</span>
<span class="nb">export</span> <span class="nv">NSC_DATA_LIMIT</span><span class="o">=</span><span class="m">100000</span> <span class="c1"># set data limit to 100,000 samples per dataset</span>
<span class="nb">export</span> <span class="nv">NSC_EXPERIMENT_DIR</span><span class="o">=</span>experiments <span class="c1"># directory path where the experiment will be saved</span>

<span class="c1">## LOCAL training</span>
<span class="c1"># start new training run using a config</span>
<span class="nv">NSC_CONFIG</span><span class="o">=</span>spell_checking/configs/sed_words.yaml spell_checking/scripts/train.sh

<span class="c1"># resume training from latest checkpoint of an experiment</span>
<span class="nv">NSC_RESUME</span><span class="o">=</span>&lt;path_to_experiment_directory&gt; spell_checking/scripts/train.sh

<span class="c1">## SLURM training</span>
<span class="c1"># starting distributed training on a SLURM cluster using sbatch</span>
<span class="c1"># requires you to set the NSC_WORLD_SIZE environment variable (total number of GPUs used for training)</span>
<span class="c1"># if you e.g. want to train on 4 nodes with 2 GPUs each set NSC_WORLD_SIZE=8</span>
<span class="nv">NSC_CONFIG</span><span class="o">=</span>spell_checking/configs/sed_words.yaml <span class="nv">NSC_WORLD_SIZE</span><span class="o">=</span><span class="m">8</span> sbatch --nodes<span class="o">=</span><span class="m">4</span> --ntasks-per-node<span class="o">=</span><span class="m">2</span> --gres<span class="o">=</span>gpu:2 spell_checking/scripts/train.sh

<span class="c1"># if you are in an interactive SLURM session (started e.g. with srun)</span>
<span class="c1"># you probably want to train as if you are running locally, set NSC_FORCE_LOCAL=true and</span>
<span class="c1"># start training without sbatch</span>
<span class="nv">NSC_FORCE_LOCAL</span><span class="o">=</span><span class="nb">true</span> <span class="nv">NSC_CONFIG</span><span class="o">=</span>spell_checking/configs/sed_words.yaml spell_checking/scripts/train.sh
</pre></div>
</div>
<p>To retrain the models of this project see the <code class="docutils literal notranslate"><span class="pre">train_slurm_&lt;task&gt;.sh</span></code> scripts in this <a class="reference external" href="https://github.com/bastiscode/spell_check/tree/main/spell_checking/scripts">directory</a> which were used for training all models.
These scripts do nothing more than setting some environment variables and calling the <a class="reference external" href="https://github.com/bastiscode/spell_check/tree/main/spell_checking/scripts/train.sh">train.sh</a>  script.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using the <code class="docutils literal notranslate"><span class="pre">train_slurm_&lt;task&gt;.sh</span></code> scripts for training is only possible on a SLURM cluster
since they call the <code class="docutils literal notranslate"><span class="pre">train.sh</span></code> script using SLURMs sbatch command.</p>
</div>
</section>
<section id="reproduce">
<h2>Reproduce<a class="headerlink" href="#reproduce" title="Permalink to this headline"></a></h2>
<p>We make all models that are needed to reproduce the results on the projects’ benchmarks available as
<a class="reference external" href="#pretrained-models">pretrained models</a>.
All pretrained models can be accessed either through the command line interface (<code class="docutils literal notranslate"><span class="pre">nsec</span></code>, <code class="docutils literal notranslate"><span class="pre">nsed</span></code>, <code class="docutils literal notranslate"><span class="pre">ntr</span></code>)
or the Python API.</p>
<p>The <a class="reference external" href="https://github.com/bastiscode/spell_check/tree/main/spell_checking/benchmarks/test">benchmarks can be found here</a> or under <code class="docutils literal notranslate"><span class="pre">/nfs/students/sebastian-walter/masters_thesis/benchmarks</span></code>.
Every benchmark follows the same directory structure:</p>
<ul class="simple">
<li><p>&lt;task&gt;/&lt;benchmark_group&gt;/&lt;benchmark_split&gt;/corrupt.txt</p></li>
<li><p>&lt;task&gt;/&lt;benchmark_group&gt;/&lt;benchmark_split&gt;/correct.txt</p></li>
</ul>
<p>Here corrupt.txt is the input containing misspelled text and correct.txt is the groundtruth output. We
provide a <a class="reference external" href="https://github.com/bastiscode/spell_check/blob/main/spell_checking/benchmarks/scripts/evaluate.py">evaluation script</a> that can be used to evaluate model predictions on a given benchmark.</p>
<p>As an example, lets look at the steps that are necessary to evaluate our gnn+ model for word level spelling error detection on
the wikidump realistic benchmark using the command line interface:</p>
<ol class="arabic simple">
<li><p>Run model on benchmark:</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>nsed -m <span class="s2">&quot;sed words:gnn+&quot;</span> <span class="se">\ </span> <span class="c1"># choose the model</span>
-f /nfs/students/sebastian-walter/masters_thesis/benchmarks/sed_words/wikidump/realistic/corrupt.txt <span class="se">\ </span> <span class="c1"># input file</span>
-o gnn_plus_predictions.txt  <span class="c1"># save output to file</span>
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>Evaluate model predictions:</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python spell_checking/benchmarks/scripts/evaluate.py <span class="se">\</span>
sed_words <span class="se">\ </span> <span class="c1"># benchmark type</span>
/nfs/students/sebastian-walter/masters_thesis/benchmarks/sed_words/wikidump/realistic/corrupt.txt <span class="se">\ </span> <span class="c1"># input file</span>
/nfs/students/sebastian-walter/masters_thesis/benchmarks/sed_words/wikidump/realistic/correct.txt <span class="se">\ </span> <span class="c1"># groundtruth file</span>
gnn_plus_predictions.txt  <span class="c1"># predicted file</span>
</pre></div>
</div>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>By default a pretrained model is downloaded as a zip file and then extracted when you first use it. Since some models
are quite large this can take some time. To cut this time all pretrained models can also be found as zip files in the directory
<code class="docutils literal notranslate"><span class="pre">/nfs/students/sebastian-walter/masters_thesis/zipped</span></code>. If you set the env variable
<code class="docutils literal notranslate"><span class="pre">NSC_DOWNLOAD_DIR</span></code> to this directory, the models are loaded from this directory and must not be downloaded first.
If you are running this project using Docker you can mount the directory to the containers download directory
by specifying an additional volume flag:
<code class="docutils literal notranslate"><span class="pre">make</span> <span class="pre">DOCKER_ARGS=&quot;-v</span> <span class="pre">/nfs/students/sebastian-walter/masters_thesis/zipped:/nsc_download&quot;</span> <span class="pre">run_docker_cpu</span></code>.</p>
</div>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>To access the benchmarks if you are running this project with Docker you can mount the benchmark directory
inside the Docker container using
<code class="docutils literal notranslate"><span class="pre">make</span> <span class="pre">DOCKER_ARGS=&quot;-v</span> <span class="pre">/nfs/students/sebastian-walter/masters_thesis/benchmarks:/benchmarks&quot;</span> <span class="pre">run_docker_cpu</span></code>.
The Docker container also provides additional commands for evaluating benchmarks that are basically
wrappers around the <a class="reference external" href="https://github.com/bastiscode/spell_check/blob/main/spell_checking/benchmarks/scripts/evaluate.py">evaluation script</a> mentioned above.</p>
</div>
</section>
</section>
<span id="document-nsc"></span><section id="module-nsc">
<span id="nsc-package"></span><h1>nsc package<a class="headerlink" href="#module-nsc" title="Permalink to this headline"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="nsc.BeamSearch">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">nsc.</span></span><span class="sig-name descname"><span class="pre">BeamSearch</span></span><a class="headerlink" href="#nsc.BeamSearch" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">nsc.api.sec.Search</span></code></p>
<p>Beam search: Maintain and expand the top beam_width paths.</p>
<dl class="py method">
<dt class="sig sig-object py" id="nsc.BeamSearch.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">beam_width</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nsc.BeamSearch.__init__" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>beam_width</strong> (<em>int</em>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="nsc.BeamSearch.beam_width">
<span class="sig-name descname"><span class="pre">beam_width</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w">  </span><span class="pre">int</span></em><em class="property"><span class="w">  </span><span class="p"><span class="pre">=</span></span><span class="w">  </span><span class="pre">5</span></em><a class="headerlink" href="#nsc.BeamSearch.beam_width" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="nsc.BestFirstSearch">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">nsc.</span></span><span class="sig-name descname"><span class="pre">BestFirstSearch</span></span><a class="headerlink" href="#nsc.BestFirstSearch" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">nsc.api.sec.Search</span></code></p>
<p>Best first search: Always expand the highest scoring path out of all paths encountered so far.</p>
<dl class="py method">
<dt class="sig sig-object py" id="nsc.BestFirstSearch.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nsc.BestFirstSearch.__init__" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="nsc.GreedySearch">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">nsc.</span></span><span class="sig-name descname"><span class="pre">GreedySearch</span></span><a class="headerlink" href="#nsc.GreedySearch" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">nsc.api.sec.Search</span></code></p>
<p>Greedy search: Always go to the highest scoring next node.</p>
<dl class="py method">
<dt class="sig sig-object py" id="nsc.GreedySearch.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nsc.GreedySearch.__init__" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="nsc.SampleSearch">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">nsc.</span></span><span class="sig-name descname"><span class="pre">SampleSearch</span></span><a class="headerlink" href="#nsc.SampleSearch" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">nsc.api.sec.Search</span></code></p>
<p>Sample search: Go to a random node of the top_k highest scoring next nodes.</p>
<dl class="py method">
<dt class="sig sig-object py" id="nsc.SampleSearch.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nsc.SampleSearch.__init__" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>top_k</strong> (<em>int</em>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="nsc.SampleSearch.top_k">
<span class="sig-name descname"><span class="pre">top_k</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w">  </span><span class="pre">int</span></em><em class="property"><span class="w">  </span><span class="p"><span class="pre">=</span></span><span class="w">  </span><span class="pre">5</span></em><a class="headerlink" href="#nsc.SampleSearch.top_k" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="nsc.Score">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">nsc.</span></span><span class="sig-name descname"><span class="pre">Score</span></span><a class="headerlink" href="#nsc.Score" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Determines how paths during/after decoding are scored/rescored.</p>
<p>The default mode “log_likelihood” is to score a candidate using the
token sequence log likelihood given as the sum of all token log probabilities.
For some search methods we optionally support normalization by the token sequence length
(so shorter paths are not preferred):</p>
<blockquote>
<div><p>score = sum(log_probabilities) / (len(log_probabilities)^alpha)</p>
</div></blockquote>
<p>Alpha here can be used to state a preference for shorter or longer sequences, if alpha &gt; 1 longer sequences are
preferred, if alpha &lt; 1 shorter sequences are preferred, and if alpha = 0 the score equals the sum of the
log probabilities.</p>
<p>Other supported modes are “dictionary” and “diff_from_input”. They only allow
candidates that either contain dictionary words only or differ from the input text.
For “dictionary” mode a prefix index must be specified, so that we are able to check if a decoded text is
a prefix of or equal to a dictionary word.</p>
<dl class="py method">
<dt class="sig sig-object py" id="nsc.Score.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">normalize_by_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'log_likelihood'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nsc.Score.__init__" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>normalize_by_length</strong> (<em>bool</em>) – </p></li>
<li><p><strong>alpha</strong> (<em>float</em>) – </p></li>
<li><p><strong>mode</strong> (<em>str</em>) – </p></li>
<li><p><strong>prefix_index</strong> (<em>Optional</em><em>[</em><em>nsc.data.index.PrefixIndex</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="nsc.Score.alpha">
<span class="sig-name descname"><span class="pre">alpha</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w">  </span><span class="pre">float</span></em><em class="property"><span class="w">  </span><span class="p"><span class="pre">=</span></span><span class="w">  </span><span class="pre">1.0</span></em><a class="headerlink" href="#nsc.Score.alpha" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="nsc.Score.mode">
<span class="sig-name descname"><span class="pre">mode</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w">  </span><span class="pre">str</span></em><em class="property"><span class="w">  </span><span class="p"><span class="pre">=</span></span><span class="w">  </span><span class="pre">'log_likelihood'</span></em><a class="headerlink" href="#nsc.Score.mode" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="nsc.Score.normalize_by_length">
<span class="sig-name descname"><span class="pre">normalize_by_length</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w">  </span><span class="pre">bool</span></em><em class="property"><span class="w">  </span><span class="p"><span class="pre">=</span></span><span class="w">  </span><span class="pre">True</span></em><a class="headerlink" href="#nsc.Score.normalize_by_length" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="nsc.Score.prefix_index">
<span class="sig-name descname"><span class="pre">prefix_index</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w">  </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">nsc.data.index.PrefixIndex</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w">  </span><span class="p"><span class="pre">=</span></span><span class="w">  </span><span class="pre">None</span></em><a class="headerlink" href="#nsc.Score.prefix_index" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="nsc.SpellingErrorCorrector">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">nsc.</span></span><span class="sig-name descname"><span class="pre">SpellingErrorCorrector</span></span><a class="headerlink" href="#nsc.SpellingErrorCorrector" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">nsc.api.utils._APIBase</span></code></p>
<p>Spelling error correction</p>
<p>Class to run spelling error correction models.</p>
<dl class="py method">
<dt class="sig sig-object py" id="nsc.SpellingErrorCorrector.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nsc.SpellingErrorCorrector.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Spelling error correction constructor.</p>
<p>Do not use this explicitly.
Use the static SpellingErrorCorrector.from_pretrained() and SpellingErrorCorrector.from_experiment() methods
instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_dir</strong> (<em>str</em>) – directory of the model to load</p></li>
<li><p><strong>device</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>int</em><em>]</em>) – device to load the model in</p></li>
<li><p><strong>kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nsc.SpellingErrorCorrector.correct_file">
<span class="sig-name descname"><span class="pre">correct_file</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_file_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_file_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">detections</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">search</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">GreedySearch()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Score(normalize_by_length=True,</span> <span class="pre">alpha=1.0,</span> <span class="pre">mode='log_likelihood',</span> <span class="pre">prefix_index=None)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_max_length_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sort_by_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nsc.SpellingErrorCorrector.correct_file" title="Permalink to this definition"></a></dt>
<dd><p>Correct spelling errors in a file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_file_path</strong> (<em>str</em>) – path to an input file, which will be corrected line by line</p></li>
<li><p><strong>output_file_path</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – path to an output file, where corrected text will be saved line by line</p></li>
<li><p><strong>detections</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em><em>]</em><em>]</em>) – spelling error detections (from a SpellingErrorDetector) to guide the correction, can either
be a path to a file containing detections or a list of lists of integers</p></li>
<li><p><strong>search</strong> (<em>nsc.api.sec.Search</em>) – Search instance to determine the search method to use for decoding</p></li>
<li><p><strong>score</strong> (<a class="reference internal" href="index.html#nsc.Score" title="nsc.api.sec.Score"><em>nsc.api.sec.Score</em></a>) – Score instance to determine how to score search paths during decoding</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – how many sequences to process at once</p></li>
<li><p><strong>batch_max_length_factor</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) – sets the maximum total length of a batch to be
batch_max_length_factor * model_max_input_length, if a model e.g. has a max input length of 512 tokens
and batch_max_length_factor is 4 then one batch will contain as many input sequences as fit within
512 * 4 = 2048 tokens (takes precedence over batch_size if specified)</p></li>
<li><p><strong>sort_by_length</strong> (<em>bool</em>) – sort the inputs by length before processing them</p></li>
<li><p><strong>show_progress</strong> (<em>bool</em>) – display progress bar</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Optional</em>[<em>List</em>[str]]</p>
</dd>
</dl>
<p>Returns: corrected file as list of strings if output_file_path is not specified else None</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nsc.SpellingErrorCorrector.correct_text">
<span class="sig-name descname"><span class="pre">correct_text</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">detections</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">search</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">GreedySearch()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Score(normalize_by_length=True,</span> <span class="pre">alpha=1.0,</span> <span class="pre">mode='log_likelihood',</span> <span class="pre">prefix_index=None)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_max_length_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sort_by_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nsc.SpellingErrorCorrector.correct_text" title="Permalink to this definition"></a></dt>
<dd><p>Correct spelling errors in text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) – text to correct given as a single string or a list of strings</p></li>
<li><p><strong>detections</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>, </em><em>List</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em><em>]</em><em>]</em>) – spelling error detections (from a SpellingErrorDetector) to guide the correction, if
inputs is a single str, detections must be a list of integers, otherwise if inputs is a list of strings,
detections should be a list of lists of integers</p></li>
<li><p><strong>search</strong> (<em>nsc.api.sec.Search</em>) – Search instance to determine the search method to use for decoding</p></li>
<li><p><strong>score</strong> (<a class="reference internal" href="index.html#nsc.Score" title="nsc.api.sec.Score"><em>nsc.api.sec.Score</em></a>) – Score instance to determine how to score search paths during decoding</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – how many sequences to process at once</p></li>
<li><p><strong>batch_max_length_factor</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) – sets the maximum total length of a batch to be
batch_max_length_factor * model_max_input_length, if a model e.g. has a max input length of 512 tokens
and batch_max_length_factor is 4 then one batch will contain as many input sequences as fit within
512 * 4 = 2048 tokens (takes precedence over batch_size if specified)</p></li>
<li><p><strong>sort_by_length</strong> (<em>bool</em>) – sort the inputs by length before processing them</p></li>
<li><p><strong>show_progress</strong> (<em>bool</em>) – display progress bar</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Union</em>[str, <em>List</em>[str]]</p>
</dd>
</dl>
<p>Returns: corrected text as string or list of strings</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nsc.SpellingErrorCorrector.from_experiment">
<em class="property"><span class="pre">static</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">from_experiment</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">experiment_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cuda'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nsc.SpellingErrorCorrector.from_experiment" title="Permalink to this definition"></a></dt>
<dd><p>Create a new NSC instance using your own experiment.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>experiment_dir</strong> (<em>str</em>) – path to the experiment directory</p></li>
<li><p><strong>device</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>int</em><em>]</em>) – device to load the model to (e.g. “cuda”, “cpu” or integer denoting GPU device index)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="index.html#nsc.SpellingErrorCorrector" title="nsc.api.sec.SpellingErrorCorrector">nsc.api.sec.SpellingErrorCorrector</a></p>
</dd>
</dl>
<p>Returns: NSC instance</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nsc.SpellingErrorCorrector.from_pretrained">
<em class="property"><span class="pre">static</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">from_pretrained</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sec'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'transformer</span> <span class="pre">words</span> <span class="pre">nmt'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cuda'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">download_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force_download</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nsc.SpellingErrorCorrector.from_pretrained" title="Permalink to this definition"></a></dt>
<dd><p>Create a new NSC instance using a pretrained model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>task</strong> (<em>str</em>) – name of the task</p></li>
<li><p><strong>model</strong> (<em>str</em>) – name of the pretrained model</p></li>
<li><p><strong>device</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>int</em><em>]</em>) – device to load the model to (e.g. “cuda”, “cpu” or integer denoting GPU device index)</p></li>
<li><p><strong>download_dir</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – directory where the compressed model will be downloaded to</p></li>
<li><p><strong>cache_dir</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – directory where the downloaded, compressed model will be extracted to</p></li>
<li><p><strong>force_download</strong> (<em>bool</em>) – force download the pretrained model again even if it already exists in the cache_dir</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="index.html#nsc.SpellingErrorCorrector" title="nsc.api.sec.SpellingErrorCorrector">nsc.api.sec.SpellingErrorCorrector</a></p>
</dd>
</dl>
<p>Returns: NSC instance</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="nsc.SpellingErrorCorrector.mixed_precision_enabled">
<em class="property"><span class="pre">property</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">mixed_precision_enabled</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w">  </span><span class="pre">bool</span></em><a class="headerlink" href="#nsc.SpellingErrorCorrector.mixed_precision_enabled" title="Permalink to this definition"></a></dt>
<dd><p>Check if mixed precision is enabled (precision is set to something else than fp32).</p>
<p>Returns: bool whether mixed precision is enabled</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="nsc.SpellingErrorCorrector.model_name">
<em class="property"><span class="pre">property</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">model_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w">  </span><span class="pre">str</span></em><a class="headerlink" href="#nsc.SpellingErrorCorrector.model_name" title="Permalink to this definition"></a></dt>
<dd><p>Gives the name of the NSC model in use.</p>
<p>Returns: name of the model</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nsc.SpellingErrorCorrector.set_precision">
<span class="sig-name descname"><span class="pre">set_precision</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">precision</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nsc.SpellingErrorCorrector.set_precision" title="Permalink to this definition"></a></dt>
<dd><p>Set the inference precision to use. Default is standard 32bit full precision.
Using 16bit floats or 16bit brain floats should only be used when you have a supported NVIDIA GPU.
When running on CPU fp16 will be overwritten with bfp16 since only bfp16 is supported on CPU for now.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>precision</strong> (<em>str</em>) – precision identifier (one of {fp32, fp16, bfp16})</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Returns: None</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nsc.SpellingErrorCorrector.suggest">
<span class="sig-name descname"><span class="pre">suggest</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">detections</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nsc.SpellingErrorCorrector.suggest" title="Permalink to this definition"></a></dt>
<dd><p>Generate suggestions for possible corrections of a text.</p>
<p>Note that if you use this with a model that translates each word individually (e.g. transformer word),
the i-th suggestion string is built by joining the i-th suggestions for all words (they do not necessarily form
a useful sentence together). To obtain n suggestions for each word in the text you can simply split every
suggestion string on whitespaces.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) – text to generate suggestions for</p></li>
<li><p><strong>n</strong> (<em>int</em>) – number of suggestions to generate</p></li>
<li><p><strong>detections</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – optional detections to exclude some words</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[str]</p>
</dd>
</dl>
<p>Returns: suggestions as list of strings</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="nsc.SpellingErrorCorrector.task_name">
<em class="property"><span class="pre">property</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">task_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w">  </span><span class="pre">str</span></em><a class="headerlink" href="#nsc.SpellingErrorCorrector.task_name" title="Permalink to this definition"></a></dt>
<dd><p>Check which NSC task is run.</p>
<p>Returns: name of the task</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nsc.SpellingErrorCorrector.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nsc.SpellingErrorCorrector.to" title="Permalink to this definition"></a></dt>
<dd><p>Move the model to a different device.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>int</em><em>]</em>) – device specifier (e.g. “cuda”, “cpu” or integer denoting GPU device index)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>nsc.api.utils._APIBase</p>
</dd>
</dl>
<p>Returns: self</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="nsc.SpellingErrorDetector">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">nsc.</span></span><span class="sig-name descname"><span class="pre">SpellingErrorDetector</span></span><a class="headerlink" href="#nsc.SpellingErrorDetector" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">nsc.api.utils._APIBase</span></code></p>
<p>Spelling error detection</p>
<p>Class to run spelling error detection models.</p>
<dl class="py method">
<dt class="sig sig-object py" id="nsc.SpellingErrorDetector.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nsc.SpellingErrorDetector.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Spelling error detection constructor.</p>
<p>Do not use this explicitly.
Use the static SpellingErrorDetector.from_pretrained() and SpellingErrorDetector.from_experiment() methods
instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_dir</strong> (<em>str</em>) – directory of the model to load</p></li>
<li><p><strong>device</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>int</em><em>]</em>) – device to load the model in</p></li>
<li><p><strong>kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nsc.SpellingErrorDetector.detect_file">
<span class="sig-name descname"><span class="pre">detect_file</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_file_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_file_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_max_length_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sort_by_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nsc.SpellingErrorDetector.detect_file" title="Permalink to this definition"></a></dt>
<dd><p>Detect spelling errors in a file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_file_path</strong> (<em>str</em>) – path to an input file, which will be checked for spelling errors line by line</p></li>
<li><p><strong>output_file_path</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – path to an output file, where the detections will be saved line by line</p></li>
<li><p><strong>threshold</strong> (<em>float</em>) – set detection threshold (0 &lt; threshold &lt; 1)</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – how many sequences to process at once</p></li>
<li><p><strong>batch_max_length_factor</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) – sets the maximum total length of a batch to be
batch_max_length_factor * model_max_input_length, if a model e.g. has a max input length of 512 tokens
and batch_max_length_factor is 4 then one batch will contain as many input sequences as fit within
512 * 4 = 2048 tokens (takes precedence over batch_size if specified)</p></li>
<li><p><strong>sort_by_length</strong> (<em>bool</em>) – sort the inputs by length before processing them</p></li>
<li><p><strong>show_progress</strong> (<em>bool</em>) – display progress bar</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Optional</em>[<em>Tuple</em>[<em>List</em>[<em>List</em>[int]], <em>List</em>[str]]]</p>
</dd>
</dl>
<dl class="simple">
<dt>Returns: tuple of detections as list of lists of integers and output strings as list of strings</dt><dd><p>if output_file_path is not specified else None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nsc.SpellingErrorDetector.detect_text">
<span class="sig-name descname"><span class="pre">detect_text</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_max_length_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sort_by_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nsc.SpellingErrorDetector.detect_text" title="Permalink to this definition"></a></dt>
<dd><p>Detect spelling errors in text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) – text to check for errors given as a single string or a list of strings</p></li>
<li><p><strong>threshold</strong> (<em>float</em>) – set detection threshold (0 &lt; threshold &lt; 1)</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – how many sequences to process at once</p></li>
<li><p><strong>batch_max_length_factor</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) – sets the maximum total length of a batch to be
batch_max_length_factor * model_max_input_length, if a model e.g. has a max input length of 512 tokens
and batch_max_length_factor is 4 then one batch will contain as many input sequences as fit within
512 * 4 = 2048 tokens (takes precedence over batch_size if specified)</p></li>
<li><p><strong>sort_by_length</strong> (<em>bool</em>) – sort the inputs by length before processing them</p></li>
<li><p><strong>show_progress</strong> (<em>bool</em>) – display progress bar</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Tuple</em>[<em>Union</em>[<em>List</em>[int], <em>List</em>[<em>List</em>[int]]], <em>Union</em>[str, <em>List</em>[str]]]</p>
</dd>
</dl>
<dl class="simple">
<dt>Returns: tuple of detections as list of integers or list of lists of integers and output strings as</dt><dd><p>str or list of strings</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nsc.SpellingErrorDetector.from_experiment">
<em class="property"><span class="pre">static</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">from_experiment</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">experiment_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cuda'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nsc.SpellingErrorDetector.from_experiment" title="Permalink to this definition"></a></dt>
<dd><p>Create a new NSC instance using your own experiment.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>experiment_dir</strong> (<em>str</em>) – path to the experiment directory</p></li>
<li><p><strong>device</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>int</em><em>]</em>) – device to load the model to (e.g. “cuda”, “cpu” or integer denoting GPU device index)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="index.html#nsc.SpellingErrorDetector" title="nsc.api.sed.SpellingErrorDetector">nsc.api.sed.SpellingErrorDetector</a></p>
</dd>
</dl>
<p>Returns: NSC instance</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nsc.SpellingErrorDetector.from_pretrained">
<em class="property"><span class="pre">static</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">from_pretrained</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sed</span> <span class="pre">words'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gnn+'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cuda'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">download_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force_download</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nsc.SpellingErrorDetector.from_pretrained" title="Permalink to this definition"></a></dt>
<dd><p>Create a new NSC instance using a pretrained model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>task</strong> (<em>str</em>) – name of the task</p></li>
<li><p><strong>model</strong> (<em>str</em>) – name of the pretrained model</p></li>
<li><p><strong>device</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>int</em><em>]</em>) – device to load the model to (e.g. “cuda”, “cpu” or integer denoting GPU device index)</p></li>
<li><p><strong>download_dir</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – directory where the compressed model will be downloaded to</p></li>
<li><p><strong>cache_dir</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – directory where the downloaded, compressed model will be extracted to</p></li>
<li><p><strong>force_download</strong> (<em>bool</em>) – force download the pretrained model again even if it already exists in the cache_dir</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="index.html#nsc.SpellingErrorDetector" title="nsc.api.sed.SpellingErrorDetector">nsc.api.sed.SpellingErrorDetector</a></p>
</dd>
</dl>
<p>Returns: NSC instance</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="nsc.SpellingErrorDetector.mixed_precision_enabled">
<em class="property"><span class="pre">property</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">mixed_precision_enabled</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w">  </span><span class="pre">bool</span></em><a class="headerlink" href="#nsc.SpellingErrorDetector.mixed_precision_enabled" title="Permalink to this definition"></a></dt>
<dd><p>Check if mixed precision is enabled (precision is set to something else than fp32).</p>
<p>Returns: bool whether mixed precision is enabled</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="nsc.SpellingErrorDetector.model_name">
<em class="property"><span class="pre">property</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">model_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w">  </span><span class="pre">str</span></em><a class="headerlink" href="#nsc.SpellingErrorDetector.model_name" title="Permalink to this definition"></a></dt>
<dd><p>Gives the name of the NSC model in use.</p>
<p>Returns: name of the model</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nsc.SpellingErrorDetector.set_precision">
<span class="sig-name descname"><span class="pre">set_precision</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">precision</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nsc.SpellingErrorDetector.set_precision" title="Permalink to this definition"></a></dt>
<dd><p>Set the inference precision to use. Default is standard 32bit full precision.
Using 16bit floats or 16bit brain floats should only be used when you have a supported NVIDIA GPU.
When running on CPU fp16 will be overwritten with bfp16 since only bfp16 is supported on CPU for now.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>precision</strong> (<em>str</em>) – precision identifier (one of {fp32, fp16, bfp16})</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Returns: None</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="nsc.SpellingErrorDetector.task_name">
<em class="property"><span class="pre">property</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">task_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w">  </span><span class="pre">str</span></em><a class="headerlink" href="#nsc.SpellingErrorDetector.task_name" title="Permalink to this definition"></a></dt>
<dd><p>Check which NSC task is run.</p>
<p>Returns: name of the task</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nsc.SpellingErrorDetector.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nsc.SpellingErrorDetector.to" title="Permalink to this definition"></a></dt>
<dd><p>Move the model to a different device.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>int</em><em>]</em>) – device specifier (e.g. “cuda”, “cpu” or integer denoting GPU device index)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>nsc.api.utils._APIBase</p>
</dd>
</dl>
<p>Returns: self</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="nsc.TokenizationRepairer">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">nsc.</span></span><span class="sig-name descname"><span class="pre">TokenizationRepairer</span></span><a class="headerlink" href="#nsc.TokenizationRepairer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">nsc.api.utils._APIBase</span></code></p>
<p>Tokenization repair</p>
<p>Class to run tokenization repair models.</p>
<dl class="py method">
<dt class="sig sig-object py" id="nsc.TokenizationRepairer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nsc.TokenizationRepairer.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Tokenization repair constructor.</p>
<p>Do not use this explicitly.
Use the static TokenizationRepairer.from_pretrained() and TokenizationRepairer.from_experiment() methods
instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_dir</strong> (<em>str</em>) – directory of the model to load</p></li>
<li><p><strong>device</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>int</em><em>]</em>) – device to load the model in</p></li>
<li><p><strong>kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nsc.TokenizationRepairer.from_experiment">
<em class="property"><span class="pre">static</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">from_experiment</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">experiment_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cuda'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nsc.TokenizationRepairer.from_experiment" title="Permalink to this definition"></a></dt>
<dd><p>Create a new NSC instance using your own experiment.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>experiment_dir</strong> (<em>str</em>) – path to the experiment directory</p></li>
<li><p><strong>device</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>int</em><em>]</em>) – device to load the model to (e.g. “cuda”, “cpu” or integer denoting GPU device index)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="index.html#nsc.TokenizationRepairer" title="nsc.api.tokenization_repair.TokenizationRepairer">nsc.api.tokenization_repair.TokenizationRepairer</a></p>
</dd>
</dl>
<p>Returns: NSC instance</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nsc.TokenizationRepairer.from_pretrained">
<em class="property"><span class="pre">static</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">from_pretrained</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'tokenization</span> <span class="pre">repair'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'eo</span> <span class="pre">large</span> <span class="pre">arxiv</span> <span class="pre">with</span> <span class="pre">errors'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cuda'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">download_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force_download</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nsc.TokenizationRepairer.from_pretrained" title="Permalink to this definition"></a></dt>
<dd><p>Create a new NSC instance using a pretrained model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>task</strong> (<em>str</em>) – name of the task</p></li>
<li><p><strong>model</strong> (<em>str</em>) – name of the pretrained model</p></li>
<li><p><strong>device</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>int</em><em>]</em>) – device to load the model to (e.g. “cuda”, “cpu” or integer denoting GPU device index)</p></li>
<li><p><strong>download_dir</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – directory where the compressed model will be downloaded to</p></li>
<li><p><strong>cache_dir</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – directory where the downloaded, compressed model will be extracted to</p></li>
<li><p><strong>force_download</strong> (<em>bool</em>) – force download the pretrained model again even if it already exists in the cache_dir</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="index.html#nsc.TokenizationRepairer" title="nsc.api.tokenization_repair.TokenizationRepairer">nsc.api.tokenization_repair.TokenizationRepairer</a></p>
</dd>
</dl>
<p>Returns: NSC instance</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="nsc.TokenizationRepairer.mixed_precision_enabled">
<em class="property"><span class="pre">property</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">mixed_precision_enabled</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w">  </span><span class="pre">bool</span></em><a class="headerlink" href="#nsc.TokenizationRepairer.mixed_precision_enabled" title="Permalink to this definition"></a></dt>
<dd><p>Check if mixed precision is enabled (precision is set to something else than fp32).</p>
<p>Returns: bool whether mixed precision is enabled</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="nsc.TokenizationRepairer.model_name">
<em class="property"><span class="pre">property</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">model_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w">  </span><span class="pre">str</span></em><a class="headerlink" href="#nsc.TokenizationRepairer.model_name" title="Permalink to this definition"></a></dt>
<dd><p>Gives the name of the NSC model in use.</p>
<p>Returns: name of the model</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nsc.TokenizationRepairer.repair_file">
<span class="sig-name descname"><span class="pre">repair_file</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_file_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_file_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_max_length_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sort_by_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nsc.TokenizationRepairer.repair_file" title="Permalink to this definition"></a></dt>
<dd><p>Repair whitespaces in a file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_file_path</strong> (<em>str</em>) – path to an input file, which will be repaired line by line</p></li>
<li><p><strong>output_file_path</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – path to an output file, where repaired text will be saved line by line</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – how many sequences to process at once</p></li>
<li><p><strong>batch_max_length_factor</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) – sets the maximum total length of a batch to be
batch_max_length_factor * model_max_input_length, if a model e.g. has a max input length of 512 tokens
and batch_max_length_factor is 4 then one batch will contain as many input sequences as fit within
512 * 4 = 2048 tokens (takes precedence over batch_size if specified)</p></li>
<li><p><strong>sort_by_length</strong> (<em>bool</em>) – sort the inputs by length before processing them</p></li>
<li><p><strong>show_progress</strong> (<em>bool</em>) – display progress bar</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Optional</em>[<em>List</em>[str]]</p>
</dd>
</dl>
<p>Returns: repaired file as list of strings if output_file_path is not specified else None</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nsc.TokenizationRepairer.repair_text">
<span class="sig-name descname"><span class="pre">repair_text</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_max_length_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sort_by_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nsc.TokenizationRepairer.repair_text" title="Permalink to this definition"></a></dt>
<dd><p>Repair whitespaces in text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) – text to repair given as a single string or a list of strings</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – how many sequences to process at once</p></li>
<li><p><strong>batch_max_length_factor</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) – sets the maximum total length of a batch to be
batch_max_length_factor * model_max_input_length, if a model e.g. has a max input length of 512 tokens
and batch_max_length_factor is 4 then one batch will contain as many input sequences as fit within
512 * 4 = 2048 tokens (takes precedence over batch_size if specified)</p></li>
<li><p><strong>sort_by_length</strong> (<em>bool</em>) – sort the inputs by length before processing them</p></li>
<li><p><strong>show_progress</strong> (<em>bool</em>) – display progress bar</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Union</em>[str, <em>List</em>[str]]</p>
</dd>
</dl>
<p>Returns: repaired text as string or list of strings</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nsc.TokenizationRepairer.set_precision">
<span class="sig-name descname"><span class="pre">set_precision</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">precision</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nsc.TokenizationRepairer.set_precision" title="Permalink to this definition"></a></dt>
<dd><p>Set the inference precision to use. Default is standard 32bit full precision.
Using 16bit floats or 16bit brain floats should only be used when you have a supported NVIDIA GPU.
When running on CPU fp16 will be overwritten with bfp16 since only bfp16 is supported on CPU for now.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>precision</strong> (<em>str</em>) – precision identifier (one of {fp32, fp16, bfp16})</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Returns: None</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="nsc.TokenizationRepairer.task_name">
<em class="property"><span class="pre">property</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">task_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w">  </span><span class="pre">str</span></em><a class="headerlink" href="#nsc.TokenizationRepairer.task_name" title="Permalink to this definition"></a></dt>
<dd><p>Check which NSC task is run.</p>
<p>Returns: name of the task</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nsc.TokenizationRepairer.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nsc.TokenizationRepairer.to" title="Permalink to this definition"></a></dt>
<dd><p>Move the model to a different device.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>int</em><em>]</em>) – device specifier (e.g. “cuda”, “cpu” or integer denoting GPU device index)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>nsc.api.utils._APIBase</p>
</dd>
</dl>
<p>Returns: self</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nsc.get_available_spelling_error_correction_models">
<span class="sig-prename descclassname"><span class="pre">nsc.</span></span><span class="sig-name descname"><span class="pre">get_available_spelling_error_correction_models</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nsc.get_available_spelling_error_correction_models" title="Permalink to this definition"></a></dt>
<dd><p>Get available spelling error correction models</p>
<p>Returns: list of spelling error correction model infos each containing the task name,
model name and a short description</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[nsc.api.utils.ModelInfo]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nsc.get_available_spelling_error_detection_models">
<span class="sig-prename descclassname"><span class="pre">nsc.</span></span><span class="sig-name descname"><span class="pre">get_available_spelling_error_detection_models</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nsc.get_available_spelling_error_detection_models" title="Permalink to this definition"></a></dt>
<dd><p>Get available spelling error detection models</p>
<p>Returns: list of spelling error detection model infos each containing the task name,
model name and a short description</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[nsc.api.utils.ModelInfo]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nsc.get_available_tokenization_repair_models">
<span class="sig-prename descclassname"><span class="pre">nsc.</span></span><span class="sig-name descname"><span class="pre">get_available_tokenization_repair_models</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nsc.get_available_tokenization_repair_models" title="Permalink to this definition"></a></dt>
<dd><p>Get available tokenization repair models</p>
<p>Returns: list of tokenization repair model infos each containing the task name, model name and a short description</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[nsc.api.utils.ModelInfo]</p>
</dd>
</dl>
</dd></dl>

</section>
</div>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Sebastian Walter.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>