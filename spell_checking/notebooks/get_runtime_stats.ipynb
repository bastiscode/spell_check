{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from typing import Any\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from nsc import SpellingErrorDetector, SpellingErrorCorrector, TokenizationRepairer\n",
    "from nsc.utils import io\n",
    "from nsc.api import utils\n",
    "\n",
    "from spell_checking import BENCHMARK_DIR, DATA_DIR, CONFIG_DIR, EXPERIMENT_DIR\n",
    "from spell_checking.baselines import sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Run experiments on runtime benchmark and record some key stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(exp: str, task: str, file_path: str, device: str, **kwargs) -> tuple:\n",
    "    start = time.perf_counter()\n",
    "    if task == \"sed\":\n",
    "        t = SpellingErrorDetector.from_experiment(exp, device)\n",
    "    elif task == \"sec\":\n",
    "        t = SpellingErrorCorrector.from_experiment(exp, device)\n",
    "    elif task == \"tokenization_repair\":\n",
    "        t = TokenizationRepairer.from_experiment(exp, device)\n",
    "    else:\n",
    "        raise RuntimeError\n",
    "    \n",
    "    with open(file_path, \"r\", encoding=\"utf8\") as inf:\n",
    "        file_bytes = len(inf.read().encode(\"utf8\"))\n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    if task == \"sed\":\n",
    "        _ = t.detect_file(file_path, **kwargs)\n",
    "    elif task == \"sec\":\n",
    "        _ = t.correct_file(file_path, **kwargs)\n",
    "    elif task == \"tokenization_repair\":\n",
    "        _ = t.repair_file(file_path, **kwargs)\n",
    "    else:\n",
    "        raise RuntimeError\n",
    "    \n",
    "    end = time.perf_counter()\n",
    "    return end - start, file_bytes\n",
    "\n",
    "\n",
    "def save_to_json(obj: object, file_path: str):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if directory:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "    with open(file_path, \"w\") as of:\n",
    "        json.dump(obj, of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "batch_size = 16\n",
    "batch_max_length_factor = 16\n",
    "os.environ[\"NSC_DATA_DIR\"] = DATA_DIR\n",
    "os.environ[\"NSC_CONFIG_DIR\"] = CONFIG_DIR\n",
    "\n",
    "runtime_benchmark = os.path.join(BENCHMARK_DIR, \"test\", \"runtime.corrupt.txt\")\n",
    "runtime_ws_benchmark = os.path.join(BENCHMARK_DIR, \"test\", \"runtime.whitespaces.corrupt.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sed_words_experiments = {\n",
    "    \"SED_WORDS/gnn_no_feat_wikidump_paragraphs_sed_words_and_sec_bookcorpus_paragraphs_sed_words_and_sec_08_04_2022_19_07_38\": \"gnn\",\n",
    "    \"SED_WORDS/transformer_no_feat_wikidump_paragraphs_sed_words_and_sec_bookcorpus_paragraphs_sed_words_and_sec_25_03_2022_14_56_24\": \"transformer\",\n",
    "    \"SED_WORDS/transformer_wikidump_paragraphs_sed_words_and_sec_bookcorpus_paragraphs_sed_words_and_sec_25_03_2022_14_56_24\": r\"transformer\\textsuperscript{+}\",\n",
    "    \"SED_WORDS/gnn_cliques_wfc_wikidump_paragraphs_sed_words_and_sec_bookcorpus_paragraphs_sed_words_and_sec_04_04_2022_10_26_13\": r\"gnn\\textsuperscript{+}\",\n",
    "    \"TOKENIZATION_REPAIR_PLUS/tokenization_repair_plus_sed_wikidump_paragraphs_tokenization_repair_plus_bookcorpus_paragraphs_tokenization_repair_plus_11_05_2022_23_10_34\": r\"tokenization repair\\textsuperscript{+}/tokenization repair\\textsuperscript{++}\"\n",
    "}\n",
    "sec_nmt_experiments = {\n",
    "    \"SEC_NMT/transformer_sec_nmt_wikidump_paragraphs_sed_words_and_sec_bookcorpus_paragraphs_sed_words_and_sec_25_03_2022_17_41_53\": \"transformer\",\n",
    "    \"SEC_WORDS_NMT/transformer_sec_words_nmt_wikidump_paragraphs_sed_words_and_sec_bookcorpus_paragraphs_sed_words_and_sec_25_03_2022_16_58_40\": \"transformer word\"\n",
    "}\n",
    "sec_ws_experiments = {\n",
    "    \"SEC_NMT/transformer_sec_with_tokenization_repair_nmt_wikidump_paragraphs_sec_with_tokenization_repair_bookcorpus_paragraphs_sec_with_tokenization_repair_26_04_2022_14_52_03\": \"transformer with tokenization repair\"\n",
    "}\n",
    "sec_tok_experiments = {\n",
    "    \"TOKENIZATION_REPAIR_PLUS/tokenization_repair_plus_sed_plus_sec_wikidump_paragraphs_tokenization_repair_plus_bookcorpus_paragraphs_tokenization_repair_plus_11_05_2022_10_47_44\": r\"tokenization repair\\textsuperscript{++}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-19 21:33:00,096 [SPELLING_ERROR_DETECTION] [INFO] [101038] running spelling error detection on device NVIDIA GeForce GTX 1080 Ti (11,178MiB memory, 6.1 compute capability, 28 multiprocessors)\n",
      "2022-05-19 21:33:10,086 [SPELLING_ERROR_DETECTION] [INFO] [101038] running spelling error detection on device NVIDIA GeForce GTX 1080 Ti (11,178MiB memory, 6.1 compute capability, 28 multiprocessors)                        \n",
      "2022-05-19 21:33:15,369 [SPELLING_ERROR_DETECTION] [INFO] [101038] running spelling error detection on device NVIDIA GeForce GTX 1080 Ti (11,178MiB memory, 6.1 compute capability, 28 multiprocessors)                        \n",
      "2022-05-19 21:33:21,432 [SPELLING_ERROR_DETECTION] [INFO] [101038] running spelling error detection on device NVIDIA GeForce GTX 1080 Ti (11,178MiB memory, 6.1 compute capability, 28 multiprocessors)                        \n",
      "2022-05-19 21:33:31,794 [SPELLING_ERROR_DETECTION] [INFO] [101038] running spelling error detection on device NVIDIA GeForce GTX 1080 Ti (11,178MiB memory, 6.1 compute capability, 28 multiprocessors)                        \n",
      "                                                                                                                                                                                                                               \r"
     ]
    }
   ],
   "source": [
    "sed_words_stats = {}\n",
    "for exp, name in sed_words_experiments.items():\n",
    "    stats = run_experiment(os.path.join(EXPERIMENT_DIR, exp), \"sed\", runtime_benchmark, device)\n",
    "    sed_words_stats[name] = stats\n",
    "\n",
    "save_to_json(sed_words_stats, \"runtime_stats/sed_words.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-19 21:48:33,644 [SPELLING_ERROR_CORRECTION] [INFO] [101038] running spelling error correction on device NVIDIA GeForce GTX 1080 Ti (11,178MiB memory, 6.1 compute capability, 28 multiprocessors)\n",
      "2022-05-19 21:49:48,047 [SPELLING_ERROR_CORRECTION] [INFO] [101038] running spelling error correction on device NVIDIA GeForce GTX 1080 Ti (11,178MiB memory, 6.1 compute capability, 28 multiprocessors)                      \n",
      "                                                                                                                                                                                                                               \r"
     ]
    }
   ],
   "source": [
    "sec_nmt_stats = {}\n",
    "for exp, name in sec_nmt_experiments.items():\n",
    "    stats = run_experiment(os.path.join(EXPERIMENT_DIR, exp), \"sec\", runtime_benchmark, device, **kwargs)\n",
    "    sec_nmt_stats[name] = stats\n",
    "\n",
    "save_to_json(sec_nmt_stats, \"runtime_stats/sec_nmt_stats.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-19 21:23:50,509 [SPELLING_ERROR_DETECTION] [INFO] [101038] running spelling error detection on device NVIDIA GeForce GTX 1080 Ti (11,178MiB memory, 6.1 compute capability, 28 multiprocessors)\n",
      "2022-05-19 21:24:00,321 [SPELLING_ERROR_DETECTION] [INFO] [101038] running spelling error detection on device NVIDIA GeForce GTX 1080 Ti (11,178MiB memory, 6.1 compute capability, 28 multiprocessors)                        \n",
      "2022-05-19 21:24:06,224 [SPELLING_ERROR_CORRECTION] [INFO] [101038] running spelling error correction on device NVIDIA GeForce GTX 1080 Ti (11,178MiB memory, 6.1 compute capability, 28 multiprocessors)                      \n",
      "2022-05-19 21:24:52,731 [SPELLING_ERROR_CORRECTION] [INFO] [101038] running spelling error correction on device NVIDIA GeForce GTX 1080 Ti (11,178MiB memory, 6.1 compute capability, 28 multiprocessors)                      \n",
      "2022-05-19 21:25:40,391 [SPELLING_ERROR_CORRECTION] [INFO] [101038] running spelling error correction on device NVIDIA GeForce GTX 1080 Ti (11,178MiB memory, 6.1 compute capability, 28 multiprocessors)                      \n",
      "2022-05-19 21:25:54,242 [SPELLING_ERROR_CORRECTION] [INFO] [101038] running spelling error correction on device NVIDIA GeForce GTX 1080 Ti (11,178MiB memory, 6.1 compute capability, 28 multiprocessors)                      \n",
      "                                                                                                                                                                                                                               \r"
     ]
    }
   ],
   "source": [
    "sed_experiment = \"SED_WORDS/gnn_cliques_wfc_wikidump_paragraphs_sed_words_and_sec_bookcorpus_paragraphs_sed_words_and_sec_04_04_2022_10_26_13\"\n",
    "start = time.perf_counter()\n",
    "sed = SpellingErrorDetector.from_experiment(\n",
    "    os.path.join(EXPERIMENT_DIR, sed_experiment), \n",
    "    device\n",
    ")\n",
    "gnn_sed_runtime = time.perf_counter() - start\n",
    "gnn_detections, _ = sed.detect_file(runtime_benchmark)\n",
    "sed_experiment = \"SED_WORDS/transformer_wikidump_paragraphs_sed_words_and_sec_bookcorpus_paragraphs_sed_words_and_sec_25_03_2022_14_56_24\"\n",
    "start = time.perf_counter()\n",
    "sed = SpellingErrorDetector.from_experiment(\n",
    "    os.path.join(EXPERIMENT_DIR, sed_experiment), \n",
    "    device\n",
    ")\n",
    "transformer_sed_runtime = time.perf_counter() - start\n",
    "transformer_detections, _ = sed.detect_file(runtime_benchmark)\n",
    "\n",
    "sec_with_sed_stats = {}\n",
    "for exp, name in sec_nmt_experiments.items():\n",
    "    runtime, file_bytes = run_experiment(os.path.join(EXPERIMENT_DIR, exp), \"sec\", runtime_benchmark, device, detections=gnn_detections)\n",
    "    sec_with_sed_stats[r\"gnn\\textsuperscript{+} $\\rightarrow$ \" + name] = (runtime + gnn_sed_runtime, file_bytes)\n",
    "    runtime, file_bytes = run_experiment(os.path.join(EXPERIMENT_DIR, exp), \"sec\", runtime_benchmark, device, detections=transformer_detections)\n",
    "    sec_with_sed_stats[r\"transformer\\textsuperscript{+} $\\rightarrow$ \" + name] = (runtime + transformer_sed_runtime, file_bytes)\n",
    "    \n",
    "save_to_json(sec_with_sed_stats, \"runtime_stats/sec_with_sed_stats.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-19 21:27:19,101 [SPELLING_ERROR_CORRECTION] [INFO] [101038] running spelling error correction on device NVIDIA GeForce GTX 1080 Ti (11,178MiB memory, 6.1 compute capability, 28 multiprocessors)\n",
      "                                                                                                                                                                                                                               \r"
     ]
    }
   ],
   "source": [
    "sec_nmt_with_tr_stats = {}\n",
    "for exp, name in sec_ws_experiments.items():\n",
    "    stats = run_experiment(os.path.join(EXPERIMENT_DIR, exp), \"sec\", runtime_ws_benchmark, device)\n",
    "    sec_nmt_with_tr_stats[name] = stats\n",
    "\n",
    "save_to_json(sec_nmt_with_tr_stats, \"runtime_stats/sec_with_tr_stats.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-19 22:06:44,989 [SPELLING_ERROR_CORRECTION] [INFO] [101038] running spelling error correction on device NVIDIA GeForce GTX 1080 Ti (11,178MiB memory, 6.1 compute capability, 28 multiprocessors)\n",
      "                                                                                                                                                                                                                               \r"
     ]
    }
   ],
   "source": [
    "sec_tok_plus_stats = {}\n",
    "for exp, name in sec_tok_experiments.items():\n",
    "    stats = run_experiment(os.path.join(EXPERIMENT_DIR, exp), \"sec\", runtime_ws_benchmark, device)\n",
    "    sec_tok_plus_stats[name] = stats\n",
    "\n",
    "save_to_json(sec_tok_plus_stats, \"runtime_stats/sec_tok_plus_stats.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-19 21:29:16,703 [TOKENIZATION_REPAIR] [INFO] [101038] running spelling error detection on device NVIDIA GeForce GTX 1080 Ti (11,178MiB memory, 6.1 compute capability, 28 multiprocessors)\n",
      "2022-05-19 21:29:22,734 [TOKENIZATION_REPAIR] [INFO] [101038] running spelling error detection on device NVIDIA GeForce GTX 1080 Ti (11,178MiB memory, 6.1 compute capability, 28 multiprocessors)                             \n",
      "2022-05-19 21:29:29,068 [TOKENIZATION_REPAIR] [INFO] [101038] running spelling error detection on device NVIDIA GeForce GTX 1080 Ti (11,178MiB memory, 6.1 compute capability, 28 multiprocessors)                             \n",
      "                                                                                                                                                                                                                               \r"
     ]
    }
   ],
   "source": [
    "tr_experiments = {\n",
    "    \"TOKENIZATION_REPAIR/eo_small_arxiv_with_errors_ported\": \"eo small\",\n",
    "    \"TOKENIZATION_REPAIR/eo_medium_arxiv_with_errors_ported\": \"eo medium\",\n",
    "    \"TOKENIZATION_REPAIR/eo_large_arxiv_with_errors_ported\": \"eo large\"\n",
    "}\n",
    "tr_stats = {}\n",
    "for exp, name in tr_experiments.items():\n",
    "    runtime, file_bytes = run_experiment(os.path.join(EXPERIMENT_DIR, exp), \"tokenization_repair\", runtime_ws_benchmark, device)\n",
    "    tr_stats[name] = (runtime, file_bytes)\n",
    "\n",
    "save_to_json(tr_stats, \"runtime_stats/tr_stats.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-19 23:15:05,761 [TOKENIZATION_REPAIR] [INFO] [115392] running tokenization repair on device NVIDIA GeForce GTX 1080 Ti (11,178MiB memory, 6.1 compute capability, 28 multiprocessors)\n",
      "2022-05-19 23:15:12,373 [SPELLING_ERROR_DETECTION] [INFO] [115392] running spelling error detection on device NVIDIA GeForce GTX 1080 Ti (11,178MiB memory, 6.1 compute capability, 28 multiprocessors)                        \n",
      "2022-05-19 23:15:17,631 [SPELLING_ERROR_CORRECTION] [INFO] [115392] running spelling error correction on device NVIDIA GeForce GTX 1080 Ti (11,178MiB memory, 6.1 compute capability, 28 multiprocessors)\n",
      "2022-05-19 23:16:03,217 [SPELLING_ERROR_CORRECTION] [INFO] [115392] running spelling error correction on device NVIDIA GeForce GTX 1080 Ti (11,178MiB memory, 6.1 compute capability, 28 multiprocessors)\n",
      "2022-05-19 23:16:16,305 [SPELLING_ERROR_DETECTION] [INFO] [115392] running spelling error detection on device NVIDIA GeForce GTX 1080 Ti (11,178MiB memory, 6.1 compute capability, 28 multiprocessors)\n",
      "2022-05-19 23:16:26,259 [SPELLING_ERROR_CORRECTION] [INFO] [115392] running spelling error correction on device NVIDIA GeForce GTX 1080 Ti (11,178MiB memory, 6.1 compute capability, 28 multiprocessors)\n",
      "2022-05-19 23:17:11,659 [SPELLING_ERROR_CORRECTION] [INFO] [115392] running spelling error correction on device NVIDIA GeForce GTX 1080 Ti (11,178MiB memory, 6.1 compute capability, 28 multiprocessors)\n",
      "2022-05-19 23:17:24,590 [SPELLING_ERROR_DETECTION] [INFO] [115392] running spelling error detection on device NVIDIA GeForce GTX 1080 Ti (11,178MiB memory, 6.1 compute capability, 28 multiprocessors)\n",
      "2022-05-19 23:17:37,489 [SPELLING_ERROR_CORRECTION] [INFO] [115392] running spelling error correction on device NVIDIA GeForce GTX 1080 Ti (11,178MiB memory, 6.1 compute capability, 28 multiprocessors)\n",
      "2022-05-19 23:18:23,520 [SPELLING_ERROR_CORRECTION] [INFO] [115392] running spelling error correction on device NVIDIA GeForce GTX 1080 Ti (11,178MiB memory, 6.1 compute capability, 28 multiprocessors)\n"
     ]
    }
   ],
   "source": [
    "tr_pipeline_stats = {}\n",
    "start = time.perf_counter()\n",
    "tok_rep = TokenizationRepairer.from_experiment(\n",
    "    os.path.join(EXPERIMENT_DIR, \"TOKENIZATION_REPAIR/eo_medium_arxiv_with_errors_ported\"), \n",
    "    device\n",
    ")\n",
    "repaired = tok_rep.repair_file(runtime_ws_benchmark)\n",
    "tr_runtime = time.perf_counter() - start\n",
    "\n",
    "runtime_ws_lines = utils.load_text_file(runtime_ws_benchmark)\n",
    "\n",
    "with open(runtime_ws_benchmark, \"r\", encoding=\"utf8\") as inf:\n",
    "    file_bytes = len(inf.read().encode(\"utf8\"))\n",
    "\n",
    "for exp, name in sed_words_experiments.items():\n",
    "    if name not in {r\"gnn\\textsuperscript{+}\", r\"transformer\\textsuperscript{+}\", r\"tokenization repair\\textsuperscript{+}/tokenization repair\\textsuperscript{++}\"}:\n",
    "        continue\n",
    "    sed = SpellingErrorDetector.from_experiment(os.path.join(EXPERIMENT_DIR, exp), device)\n",
    "    start = time.perf_counter()\n",
    "    detections, new_repaired = sed.detect_text(repaired if not name.startswith(\"tokenization\") else runtime_ws_lines)\n",
    "    sed_runtime = time.perf_counter() - start\n",
    "    for sec_exp, sec_name in sec_nmt_experiments.items():\n",
    "        sec = SpellingErrorCorrector.from_experiment(os.path.join(EXPERIMENT_DIR, sec_exp), device)\n",
    "        start = time.perf_counter()\n",
    "        _ = sec.correct_text(repaired if not name.startswith(\"tokenization\") else new_repaired, detections=detections)\n",
    "        sec_runtime = time.perf_counter() - start\n",
    "        runtime = sed_runtime + sec_runtime\n",
    "        pipeline_names = []\n",
    "        if not name.startswith(\"tokenization\"):\n",
    "            runtime += tr_runtime\n",
    "            pipeline_names = [\"eo medium\", name]\n",
    "        else:\n",
    "            pipeline_names = [r\"tokenization repair\\textsuperscript{+}\"]\n",
    "        tr_pipeline_stats[r\" $\\rightarrow$ \".join(pipeline_names + [sec_name])] = (runtime, file_bytes)\n",
    "\n",
    "save_to_json(tr_pipeline_stats, \"runtime_stats/tr_pipeline_stats.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data folder is set to `/home/sebastian/anaconda3/envs/masters_thesis/lib/python3.8/site-packages/neuspell/../data` script\n",
      "loading vocab from path:/home/sebastian/anaconda3/envs/masters_thesis/lib/python3.8/site-packages/neuspell/../data/checkpoints/subwordbert-probwordnoise/vocab.pkl\n",
      "initializing model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubwordBert(\n",
      "  (bert_dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bert_model): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dense): Linear(in_features=768, out_features=100002, bias=True)\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n",
      "185211810\n",
      "loading pretrained weights from path:/home/sebastian/anaconda3/envs/masters_thesis/lib/python3.8/site-packages/neuspell/../data/checkpoints/subwordbert-probwordnoise\n",
      "Loading model params from checkpoint dir: /home/sebastian/anaconda3/envs/masters_thesis/lib/python3.8/site-packages/neuspell/../data/checkpoints/subwordbert-probwordnoise\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29749e8054da40dfb26b3d75f0935ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "running neuspell baseline neuspell_bert on runtime benchmark:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "neuspell = sec.SECNeuspellBaseline(\"bert\")\n",
    "neuspell_stats = {}\n",
    "\n",
    "with open(runtime_benchmark, \"r\", encoding=\"utf8\") as inf:\n",
    "    file_bytes = len(inf.read().encode(\"utf8\"))\n",
    "    \n",
    "start = time.perf_counter()\n",
    "batch_size = 16\n",
    "inputs = utils.load_text_file(runtime_benchmark)\n",
    "inputs = sorted(inputs, key=lambda s: len(s))\n",
    "for i in tqdm(list(range(0, len(inputs), batch_size)), desc=f\"running neuspell baseline {neuspell.name} on runtime benchmark\"):\n",
    "    batch_inputs = inputs[i:i+batch_size]\n",
    "    _ = neuspell.inference(batch_inputs)\n",
    "end = time.perf_counter()\n",
    "\n",
    "neuspell_stats[\"neuspell bert\"] = (end - start, file_bytes)\n",
    "save_to_json(neuspell_stats, \"runtime_stats/sec_neuspell.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
