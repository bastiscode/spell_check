{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "035aeb06-d614-4dfe-adc6-63973e402f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aa1f1e4-772d-4ecb-8c70-9bac5166cb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from spelling_correction import DATA_DIR, BENCHMARK_DIR\n",
    "\n",
    "from gnn_lib.data import tokenization, utils\n",
    "from gnn_lib.utils import io\n",
    "from gnn_lib.api.utils import load_text_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c611226d-dba1-4a8f-b952-11b025b064ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenization.BPETokenizer(\n",
    "    cfg=tokenization.TokenizerConfig(type=tokenization.Tokenizers.BPE, file_path=os.path.join(DATA_DIR, \"tokenizers\", \"bpe\", \"wiki_bookcorpus_10k_no_prefix_space.pkl\"))\n",
    ")\n",
    "char_tokenizer = tokenization.CharTokenizer()\n",
    "\n",
    "tok_fn = tokenization.get_tokenization_fn(tokenizer)\n",
    "char_tok_fn = tokenization.get_tokenization_fn(char_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4decbe60-c231-4329-acba-82ae9bd08398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/sebastian/msc/masters_thesis/code/spelling_correction/benchmarks/test/sec/wikidump/artificial/corrupt.txt',\n",
       " '/home/sebastian/msc/masters_thesis/code/spelling_correction/benchmarks/test/sec/wikidump/realistic/corrupt.txt',\n",
       " '/home/sebastian/msc/masters_thesis/code/spelling_correction/benchmarks/test/sec/bookcorpus/artificial/corrupt.txt',\n",
       " '/home/sebastian/msc/masters_thesis/code/spelling_correction/benchmarks/test/sec/bookcorpus/realistic/corrupt.txt',\n",
       " '/home/sebastian/msc/masters_thesis/code/spelling_correction/benchmarks/test/sec/neuspell/bea60k/corrupt.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarks = io.glob_safe(os.path.join(BENCHMARK_DIR, \"test\", \"sec\", \"*\", \"*\", \"corrupt.txt\"))\n",
    "benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "419ca2b1-1ab3-4cb8-9d8b-c01f357d8139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trans_edges(tokens: list) -> int:\n",
    "    return sum(len(t) for t in tokens) ** 2\n",
    "\n",
    "def get_gnn_edges(tokens: list) -> int:\n",
    "    return len(tokens) ** 2 + sum(len(t) * (len(t) + 1) for t in tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4354b2b7-d1cd-4c56-b006-9c0f65126106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_statistics(benchmarks: list, tok_fn) -> tuple:\n",
    "    total_tokens = 0\n",
    "    total_words = 0\n",
    "    total_sequences = 0\n",
    "    trans_edges = 0\n",
    "    gnn_edges = 0\n",
    "    for benchmark in tqdm(benchmarks, desc=\"tokenizing benchmarks\"):\n",
    "        inputs = load_text_file(benchmark)\n",
    "        tokenized = utils.tokenize_words_batch(inputs, return_docs=True)\n",
    "        for _, doc in tokenized:\n",
    "            tokens = tok_fn(doc)\n",
    "            total_words += len(tokens)\n",
    "            total_tokens += sum(len(t) for t in tokens)\n",
    "            total_sequences += 1\n",
    "            trans_edges += get_trans_edges(tokens)\n",
    "            gnn_edges += get_gnn_edges(tokens)\n",
    "    return total_tokens / total_words, total_words / total_sequences, trans_edges / total_sequences, gnn_edges / total_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e347565c-6dea-43ff-8215-13a96c43b015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_and_gnn_edges(avg_number_of_tokens_per_word: float, avg_number_of_words_per_sequence: float) -> float:\n",
    "    transformer_num_edges = (avg_number_of_tokens_per_word * avg_number_of_words_per_sequence) ** 2\n",
    "    gnn_num_edges = (\n",
    "        avg_number_of_words_per_sequence ** 2 # word fully connected\n",
    "        + avg_number_of_words_per_sequence * (avg_number_of_tokens_per_word ** 2) # token inside word fully connected\n",
    "        + avg_number_of_words_per_sequence * avg_number_of_tokens_per_word # token to word\n",
    "    )\n",
    "    return transformer_num_edges, gnn_num_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0afe61-946c-4be1-a30a-4576e941929b",
   "metadata": {},
   "source": [
    "#### BPE tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "daaddfa9-a728-40ec-9d11-7b7f3d992950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ad9fb74e584a0e8d2df5388eeffb4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizing benchmarks:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_number_of_tokens_per_word, avg_number_of_words_per_sequence, t_edges, g_egdes = get_avg_statistics(benchmarks, tok_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd13b4b2-0f42-4512-9ad5-367f9bed60c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.4368753332523339, 25.080334614339506, 4045.239053219984, 1885.6976437250107)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_number_of_tokens_per_word, avg_number_of_words_per_sequence, t_edges, g_egdes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9aee951-decc-4f55-80de-61e9a495097d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1298.6880116545738, 716.8416263132389)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_and_gnn_edges(avg_number_of_tokens_per_word, avg_number_of_words_per_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cecc38-5090-4208-9b37-5045ac8a33b3",
   "metadata": {},
   "source": [
    "#### Char tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4b3b712-fec5-405e-80a1-cc329cbfa619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8bffa1a0e724b1490da7307156e0656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizing benchmarks:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_number_of_tokens_per_word, avg_number_of_words_per_sequence, t_edges, g_egdes = get_avg_statistics(benchmarks, char_tok_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ace090ac-360d-4b3c-89e8-6349791d7858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.861724175023932, 25.080334614339506, 45033.58500252319, 2693.3270641667636)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_number_of_tokens_per_word, avg_number_of_words_per_sequence, t_edges, g_egdes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df6ecb42-f4b4-4ab3-a500-ab05cd51e66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14867.819663169304, 1343.764720351728)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_and_gnn_edges(avg_number_of_tokens_per_word, avg_number_of_words_per_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9937155d-3341-4ddf-bc3c-ba9dd3b77338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
