{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaee401f-698a-419e-b191-67ca95b5c1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ec6b54da-309e-4da2-b940-a6b3608e0562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Set, Union, Dict\n",
    "import difflib\n",
    "import Levenshtein\n",
    "import re\n",
    "import pprint\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "feacc19d-b0e7-44a6-92a2-3de34f0a58e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_operations(\n",
    "    a: str, \n",
    "    b: str, \n",
    "    with_swap: bool = False, \n",
    "    spaces_insert_delete_only: bool = False, \n",
    "    return_distance_only: bool = False\n",
    ") -> Union[int, List[Tuple[str, int, int]]]:\n",
    "    \"\"\"\n",
    "    Returns the edit operations transforming a into b, optionally allowing only insertion and deletion operations for spaces.\n",
    "    Follows optimal string alignment distance at https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance.\n",
    "    \n",
    "    \"\"\"\n",
    "    d = [\n",
    "        list(range(len(b) + 1)) if i == 0 else [i if j == 0 else -1 for j in range(len(b) + 1)]\n",
    "        for i in range(len(a) + 1)\n",
    "    ]\n",
    "    # operations: ' ' --> not yet filled in, k --> keep, i --> insert, d --> delete, r --> replace, s --> swap\n",
    "    ops = [\n",
    "        [\"i\"] * (len(b) + 1) if i == 0 else [\"d\" if j == 0 else \" \" for j in range(len(b) + 1)]\n",
    "        for i in range(len(a) + 1)\n",
    "    ]\n",
    "    ops[0][0] = \"k\"\n",
    "    \n",
    "    # fill in matrices\n",
    "    for i in range(1, len(a) + 1):\n",
    "        for j in range(1, len(b) + 1):\n",
    "            # string indices are offset by -1\n",
    "            i_str = i - 1\n",
    "            j_str = j - 1\n",
    "            \n",
    "            # delete and insert\n",
    "            costs = [(d[i-1][j] + 1, \"d\"), (d[i][j-1] + 1, \"i\")]\n",
    "            if a[i_str] == b[j_str]:\n",
    "                costs.append((d[i-1][j-1], \"k\"))\n",
    "            else:\n",
    "                # chars are not equal, only allow replacement if no space is involved or we are allowed to replace spaces\n",
    "                if (\n",
    "                    not spaces_insert_delete_only \n",
    "                    or (a[i_str] != \" \" and b[j_str] != \" \")\n",
    "                ):\n",
    "                    costs.append((d[i-1][j-1] + 1, \"r\"))\n",
    "            # check if we can swap chars, that is if we are allowed to swap and if the chars to swap match\n",
    "            if with_swap and i > 1 and j > 1 and a[i_str] == b[j_str-1] and a[i_str-1] == b[j_str]:\n",
    "                # we can swap the chars, but only allow swapping if no space is involved or we are allowed to swap spaces\n",
    "                if (\n",
    "                    not spaces_insert_delete_only \n",
    "                    or (a[i_str] != \" \" and a[i_str - 1] != \" \")\n",
    "                ):\n",
    "                    costs.append((d[i-2][j-2] + 1, \"s\"))\n",
    "                \n",
    "            min_cost, min_op = min(costs, key=lambda item: item[0])\n",
    "            d[i][j] = min_cost\n",
    "            ops[i][j] = min_op\n",
    "    \n",
    "    # make sure that it worked\n",
    "    assert all(v >= 0 for row in d for v in row)\n",
    "    \n",
    "    if return_distance_only:\n",
    "        return d[-1][-1]\n",
    "    \n",
    "    # backtrace matrices\n",
    "    edit_ops = []\n",
    "    i = len(a)\n",
    "    j = len(b)\n",
    "    while i > 0 or j > 0:\n",
    "        op = ops[i][j]\n",
    "        if op == \"k\":\n",
    "            # we do not add keep operation to edit_ops\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "            continue\n",
    "            \n",
    "        if op == \"d\":\n",
    "            op_name = \"delete\"\n",
    "            i -= 1\n",
    "        elif op == \"i\":\n",
    "            op_name = \"insert\"\n",
    "            j -= 1\n",
    "        elif op == \"r\":\n",
    "            op_name = \"replace\"\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif op == \"s\":\n",
    "            op_name = \"swap\"\n",
    "            i -= 2\n",
    "            j -= 2\n",
    "        else:\n",
    "            raise RuntimeError(\"should not happen\")\n",
    "            \n",
    "        edit_ops.append((op_name, i, j))\n",
    "    \n",
    "    return list(reversed(edit_ops))\n",
    "\n",
    "def edit_distance(\n",
    "    a: str, \n",
    "    b: str, \n",
    "    with_swap: bool = True, \n",
    "    spaces_insert_delete_only: bool = False\n",
    ") -> int:\n",
    "    return edit_operations(a, b, with_swap, spaces_insert_delete_only, return_distance_only=True)\n",
    "    \n",
    "edit_ops = edit_operations(test_ipt, test_tgt)\n",
    "lev_edit_ops = Levenshtein.editops(test_ipt, test_tgt)\n",
    "assert edit_ops == lev_edit_ops, (edit_ops, lev_edit_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1d38a264-4692-4f81-a173-13061ee00698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word_boundaries(s: str) -> List[Tuple[int, int]]:\n",
    "    word_boundary_pattern = re.compile(\"\\S+\")\n",
    "    matches = [(match.start(), match.end()) for match in word_boundary_pattern.finditer(s)]\n",
    "    assert len(matches) == len(s.split())\n",
    "    return matches\n",
    "\n",
    "def get_edited_words(ipt: str, tgt: str) -> Set[int]:\n",
    "    assert tgt.strip() == tgt and ipt.strip() == ipt, \"the two strings must not contain leading or trailing whitespaces\"\n",
    "    tgt_word_boundaries = find_word_boundaries(tgt)\n",
    "    edit_ops = edit_operations(ipt, tgt, spaces_insert_delete_only=True)\n",
    "    edited_tgt_indices = set()\n",
    "    for op_code, ipt_idx, tgt_idx in edit_ops:\n",
    "        word_boundary_idx = 0\n",
    "        while word_boundary_idx < len(tgt_word_boundaries):\n",
    "            word_start, word_end = tgt_word_boundaries[word_boundary_idx]\n",
    "            if tgt_idx <= word_end:\n",
    "                break\n",
    "            word_boundary_idx += 1\n",
    "            \n",
    "        if op_code == \"insert\" and tgt[tgt_idx] == \" \":\n",
    "            assert word_boundary_idx < len(tgt_word_boundaries) - 1\n",
    "            edited_tgt_indices.add(word_boundary_idx)\n",
    "            edited_tgt_indices.add(word_boundary_idx + 1)\n",
    "        else:\n",
    "            edited_tgt_indices.add(word_boundary_idx)\n",
    "            \n",
    "    return edited_tgt_indices\n",
    "\n",
    "def match_words(pred: str, tgt: str) -> Set[int]:\n",
    "    sm = difflib.SequenceMatcher(a=pred.split(), b=tgt.split())\n",
    "    matching_blocks = sm.get_matching_blocks()\n",
    "    matching_pred_indices = set()\n",
    "    matching_tgt_indices = set()\n",
    "    for matching_block in matching_blocks:\n",
    "        start_pred = matching_block.a\n",
    "        for idx in range(start_pred, start_pred + matching_block.size):\n",
    "            matching_pred_indices.add(idx)\n",
    "        start_tgt = matching_block.b\n",
    "        for idx in range(start_tgt, start_tgt + matching_block.size):\n",
    "            matching_tgt_indices.add(idx)\n",
    "    return matching_pred_indices, matching_tgt_indices\n",
    "\n",
    "def group_words(\n",
    "    ipt: str, \n",
    "    pred: str,\n",
    "    matching_in_pred: Set[int]\n",
    ") -> Set[int]:\n",
    "    assert pred.strip() == pred and ipt.strip() == ipt, \"the two strings must not contain leading or trailing whitespaces\"\n",
    "    edit_ops = edit_operations(ipt, pred, spaces_insert_delete_only=True)\n",
    "    ipt_word_boundaries = find_word_boundaries(ipt)\n",
    "    merged_with_next_indices = set()\n",
    "    num_spaces_inserted = {}\n",
    "    for op_code, ipt_idx, pred_idx in edit_ops:\n",
    "        word_boundary_idx = 0\n",
    "        while word_boundary_idx < len(ipt_word_boundaries):\n",
    "            word_start, word_end = ipt_word_boundaries[word_boundary_idx]\n",
    "            if ipt_idx <= word_end:\n",
    "                break\n",
    "            word_boundary_idx += 1\n",
    "            \n",
    "        if op_code == \"delete\" and ipt[ipt_idx] == \" \":\n",
    "            merged_with_next_indices.add(word_boundary_idx)\n",
    "        \n",
    "        if op_code == \"insert\" and pred[pred_idx] == \" \":\n",
    "            if word_boundary_idx not in num_spaces_inserted:\n",
    "                num_spaces_inserted[word_boundary_idx] = 1\n",
    "            else:\n",
    "                num_spaces_inserted[word_boundary_idx] += 1\n",
    "    \n",
    "    correct = set()\n",
    "    ipt_idx = 0\n",
    "    pred_idx = 0\n",
    "    while ipt_idx < len(ipt_word_boundaries):\n",
    "        merged_word = {ipt_idx}\n",
    "        total_spaces_inserted = num_spaces_inserted.get(ipt_idx, 0)\n",
    "        while ipt_idx in merged_with_next_indices:\n",
    "            ipt_idx += 1\n",
    "            merged_word.add(ipt_idx)\n",
    "            total_spaces_inserted += num_spaces_inserted.get(ipt_idx, 0)\n",
    "            \n",
    "        # find corresponding words for merged word in pred\n",
    "        if all(idx in matching_in_pred for idx in range(pred_idx, pred_idx + total_spaces_inserted + 1)):\n",
    "            correct = correct.union(merged_word)\n",
    "            \n",
    "        ipt_idx += 1\n",
    "        pred_idx += total_spaces_inserted + 1\n",
    "        \n",
    "    assert ipt_idx == len(ipt_word_boundaries) and pred_idx == len(pred.split())\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "69ae1c13-2598-45c6-9077-2ba8e83375ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = \"The cute act eats delicate fi sh.\"\n",
    "test_predicted = [test_pred]\n",
    "test_tgt = \"The cute cat eats delicious fish.\"\n",
    "test_target = [test_tgt]\n",
    "test_ipt = \"Te cute cteats delicious fi sh.\"\n",
    "test_inputs = [test_ipt]\n",
    "\n",
    "misspelled = {0, 2, 3, 5}\n",
    "restored = {0, 1, 3}\n",
    "changed = {0, 2, 3}\n",
    "correct = {0, 1}\n",
    "\n",
    "edited_in_tgt = get_edited_words(test_ipt, test_tgt)\n",
    "assert misspelled == edited_in_tgt, (misspelled, edited_in_tgt)\n",
    "assert len(misspelled) <= len(test_tgt.split())\n",
    "\n",
    "edited_in_ipt = get_edited_words(test_pred, test_ipt)\n",
    "assert changed == edited_in_ipt, (changed, edited_in_ipt)\n",
    "assert len(changed) <= len(test_ipt.split())\n",
    "\n",
    "matching_in_pred, matching_in_tgt = match_words(test_pred, test_tgt)\n",
    "assert restored == matching_in_tgt, (restored, matching_in_tgt)\n",
    "assert len(restored) <= len(test_tgt.split())\n",
    "\n",
    "correct_in_ipt = group_words(test_ipt, test_pred, matching_in_pred)\n",
    "assert correct == correct_in_ipt\n",
    "assert len(correct) <= len(test_ipt.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9a9c367d-4875-4f5d-a97f-e48fe3f6d0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correction_f1_prec_rec(predicted_sequences: List[str], target_sequences: List[str], input_sequences: List[str]) -> Tuple[float, float, float]:\n",
    "    def _tp_fp_fn(pred: str, tgt: str, ipt: str) -> Tuple[int, int, int]:\n",
    "        misspelled = get_edited_words(ipt, tgt)\n",
    "        changed = get_edited_words(pred, ipt)\n",
    "        matching_in_pred, restored = match_words(pred, tgt)\n",
    "        correct = group_words(ipt, pred, matching_in_pred)\n",
    "        tp = misspelled.intersection(restored)\n",
    "        fn = misspelled.difference(restored)\n",
    "        fp = changed.difference(correct)\n",
    "        return len(tp), len(fp), len(fn)\n",
    "        \n",
    "    total_tp = total_fp = total_fn = 0\n",
    "    for pred, tgt, ipt in zip(predicted_sequences, target_sequences, input_sequences):\n",
    "        tp, fp, fn = _tp_fp_fn(pred, tgt, ipt)\n",
    "        total_tp += tp\n",
    "        total_fp += fp\n",
    "        total_fn += fn\n",
    "    \n",
    "    return total_tp, total_fp, total_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fa0f9d2f-c580-49ac-9599-5258f48e386b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 15.527977000601823ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 2, 2)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_prec_rec(test_predicted, test_target, test_inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
