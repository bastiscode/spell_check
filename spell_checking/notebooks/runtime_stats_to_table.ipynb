{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ff6fa9-0c1d-4c03-bffe-64de2d4d3f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6b0cc18-d6e8-49e9-99d9-ad6eccf1e4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from nsc.api import tables\n",
    "from nsc.api import utils\n",
    "from nsc.utils import io\n",
    "\n",
    "from spell_checking import BENCHMARK_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf527c4c-f070-45d6-b3c5-fded040e720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_data(file_path: str, task: str) -> tuple:\n",
    "    data = []\n",
    "    runtimes = []\n",
    "    with open(file_path, \"r\") as inf:\n",
    "        json_data = json.load(inf)\n",
    "        for model in sorted(json_data):\n",
    "            runtime, file_size = json_data[model]\n",
    "            kbs = (file_size / 1000) / runtime\n",
    "            data.append([task, model, f\"{runtime:.1f}\", f\"{kbs:.1f}\"])\n",
    "            runtimes.append(runtime)\n",
    "    return data, runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c53689b1-71cb-4fc8-96b4-20ae552212f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Task | Model/Pipeline | Runtime in s | kB/s |\n",
      "| :-- | --: | --: | --: |\n",
      "| TR | eo large | 7.9 | 29.9 |\n",
      "| TR | eo medium | 6.1 | 38.5 |\n",
      "| TR | eo small | 5.8 | 40.4 |\n",
      "| SEDS/SEDW | tokenization repair\\textsuperscript{+}/tokenization repair\\textsuperscript{++} | 13.1 | 18.0 |\n",
      "| SEDS/SEDW | gnn\\textsuperscript{+} | 9.7 | 24.3 |\n",
      "| SEDS/SEDW | gnn | 9.2 | 25.7 |\n",
      "| SEDS/SEDW | transformer\\textsuperscript{+} | 5.6 | 42.3 |\n",
      "| SEDS/SEDW | transformer | 4.8 | 49.5 |\n",
      "| SEC | transformer | 73.5 | 3.2 |\n",
      "| SEDW $\\rightarrow$ SEC | transformer\\textsuperscript{+} $\\rightarrow$ transformer | 47.2 | 5.0 |\n",
      "| SEDW $\\rightarrow$ SEC | gnn\\textsuperscript{+} $\\rightarrow$ transformer | 46.4 | 5.1 |\n",
      "| SEC | transformer word | 37.2 | 6.4 |\n",
      "| SEC | neuspell bert | 21.8 | 10.8 |\n",
      "| SEDW $\\rightarrow$ SEC | gnn\\textsuperscript{+} $\\rightarrow$ transformer word | 13.7 | 17.3 |\n",
      "| SEDW $\\rightarrow$ SEC | transformer\\textsuperscript{+} $\\rightarrow$ transformer word | 13.5 | 17.5 |\n",
      "| TR \\& SEC | transformer with tokenization repair | 83.1 | 2.8 |\n",
      "| TR $\\rightarrow$ SEDW $\\rightarrow$ SEC | eo medium $\\rightarrow$ gnn\\textsuperscript{+} $\\rightarrow$ transformer | 60.7 | 3.9 |\n",
      "| TR $\\rightarrow$ SEDW $\\rightarrow$ SEC | eo medium $\\rightarrow$ transformer\\textsuperscript{+} $\\rightarrow$ transformer | 57.2 | 4.1 |\n",
      "| TR $\\rightarrow$ SEDW $\\rightarrow$ SEC | eo medium $\\rightarrow$ gnn\\textsuperscript{+} $\\rightarrow$ transformer word | 28.6 | 8.3 |\n",
      "| TR $\\rightarrow$ SEDW $\\rightarrow$ SEC | tokenization repair\\textsuperscript{++} | 24.4 | 9.7 |\n",
      "| TR $\\rightarrow$ SEDW $\\rightarrow$ SEC | eo medium $\\rightarrow$ transformer\\textsuperscript{+} $\\rightarrow$ transformer word | 24.1 | 9.8 |\n"
     ]
    }
   ],
   "source": [
    "headers = [[\"Task\", \"Model/Pipeline\", \"Runtime in s\", \"kB/s\"]]\n",
    "data = []\n",
    "horizontal_lines = []\n",
    "\n",
    "tr_data = get_table_data(\"runtime_stats/tr_stats.json\", \"TR\")\n",
    "tr_data, _ = list(zip(*sorted(list(zip(*tr_data)), key=lambda e: e[1], reverse=True)))\n",
    "data.extend(tr_data)\n",
    "horizontal_lines.extend([False] * (len(tr_data) - 1) + [True])\n",
    "\n",
    "sed_words_data = get_table_data(\"runtime_stats/sed_words.json\", \"SEDS/SEDW\")\n",
    "sed_words_data, _ = list(zip(*sorted(list(zip(*sed_words_data)), key=lambda e: e[1], reverse=True)))\n",
    "data.extend(sed_words_data)\n",
    "horizontal_lines.extend([False] * (len(sed_words_data) - 1) + [True])\n",
    "\n",
    "sec_data, sec_runtimes = get_table_data(\"runtime_stats/sec_nmt_stats.json\", \"SEC\")\n",
    "\n",
    "sec_with_sed_data, sec_with_sed_runtimes = get_table_data(\"runtime_stats/sec_with_sed_stats.json\", r\"SEDW $\\rightarrow$ SEC\")\n",
    "sec_data.extend(sec_with_sed_data)\n",
    "sec_runtimes.extend(sec_with_sed_runtimes)\n",
    "\n",
    "sec_neuspell_data, sec_neuspell_runtimes = get_table_data(\"runtime_stats/sec_neuspell.json\", \"SEC\")\n",
    "sec_data.extend(sec_neuspell_data)\n",
    "sec_runtimes.extend(sec_neuspell_runtimes)\n",
    "\n",
    "sec_data, _ = list(zip(*sorted(list(zip(sec_data, sec_runtimes)), key=lambda e: e[1], reverse=True)))\n",
    "data.extend(sec_data)\n",
    "horizontal_lines.extend([False] * (len(sec_data) - 1) + [True])\n",
    "\n",
    "sec_with_tr_data, sec_with_tr_runtimes = get_table_data(\"runtime_stats/sec_with_tr_stats.json\", r\"TR \\& SEC\")\n",
    "\n",
    "sec_tok_plus_data, sec_tok_plus_runtimes = get_table_data(\"runtime_stats/sec_tok_plus_stats.json\", r\"TR $\\rightarrow$ SEDW $\\rightarrow$ SEC\")\n",
    "sec_with_tr_data.extend(sec_tok_plus_data)\n",
    "sec_with_tr_runtimes.extend(sec_tok_plus_runtimes)\n",
    "\n",
    "sec_tr_pipe_data, sec_tr_pipe_runtimes = get_table_data(\"runtime_stats/tr_pipeline_stats.json\", r\"TR $\\rightarrow$ SEDW $\\rightarrow$ SEC\")\n",
    "sec_with_tr_data.extend(sec_tr_pipe_data)\n",
    "sec_with_tr_runtimes.extend(sec_tr_pipe_runtimes)\n",
    "\n",
    "sec_with_tr_data, _ = list(zip(*sorted(list(zip(sec_with_tr_data, sec_with_tr_runtimes)), key=lambda e: e[1], reverse=True)))\n",
    "\n",
    "data.extend(sec_with_tr_data)\n",
    "horizontal_lines.extend([False] * (len(sec_with_tr_data) - 1) + [True])\n",
    "\n",
    "latex_table = tables.generate_table(\n",
    "    headers,\n",
    "    data,\n",
    "    horizontal_lines=horizontal_lines,\n",
    "    fmt=\"latex\"\n",
    ")\n",
    "utils.save_text_file(os.path.join(BENCHMARK_DIR, \"test\", \"runtime_tables\", \"runtimes_generated.tex\"), [latex_table])\n",
    "print(tables.generate_table(\n",
    "    headers,\n",
    "    data,\n",
    "    horizontal_lines=horizontal_lines,\n",
    "    fmt=\"markdown\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729c54b5-7497-4d06-922e-80ff1ea8789c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
