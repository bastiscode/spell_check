{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1f5b259-24a7-4f99-acbc-e16680577df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b28bbf22-1677-41bb-bcee-254c01b1d7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from nsc.api import utils\n",
    "from nsc.data import preprocessing\n",
    "\n",
    "from spell_checking import BENCHMARK_DIR, MISSPELLINGS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8909d517-3d66-40e4-890c-cd6adc132898",
   "metadata": {},
   "outputs": [],
   "source": [
    "own_benchmarks = [\"wikidump/realistic\", \"wikidump/artificial\", \"bookcorpus/realistic\", \"bookcorpus/artificial\"]\n",
    "neuspell_benchmarks = [\"neuspell/bea322\", \"neuspell/bea4660\", \"neuspell/bea60k\", \"neuspell/jfleg\"]\n",
    "\n",
    "def generate_combined_benchmark(benchmarks, samples_per_benchmark):\n",
    "    rand = np.random.default_rng(22)\n",
    "    correct_lines = []\n",
    "    corrupt_lines = []\n",
    "    lowercase_only = []\n",
    "    for benchmark in sorted(benchmarks):\n",
    "        corrupt = utils.load_text_file(os.path.join(BENCHMARK_DIR, \"test\", \"sec\", benchmark, \"corrupt.txt\"))\n",
    "        correct = utils.load_text_file(os.path.join(BENCHMARK_DIR, \"test\", \"sec\", benchmark, \"correct.txt\"))\n",
    "        indices = rand.permutation(len(corrupt))[:samples_per_benchmark]\n",
    "        correct_lines.extend([correct[idx] for idx in indices])\n",
    "        corrupt_lines.extend([corrupt[idx] for idx in indices])\n",
    "        lowercase_only.extend([\"1\"] * len(indices) if benchmark in {\"neuspell/bea322\", \"neuspell/bea4660\"} else [\"0\"] * len(indices))\n",
    "    return correct_lines, corrupt_lines, lowercase_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6afabb21-4b1f-40ca-9e53-75b1429d3624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined benchmark from our own benchmarks\n",
    "own_correct, own_corrupt, _ = generate_combined_benchmark(own_benchmarks, 200)\n",
    "print(len(own_correct))\n",
    "utils.save_text_file(os.path.join(BENCHMARK_DIR, \"test\", \"sec\", \"spelling_correction\", \"wikibook\", \"correct.txt\"), own_correct)\n",
    "utils.save_text_file(os.path.join(BENCHMARK_DIR, \"test\", \"sec\", \"spelling_correction\", \"wikibook\", \"corrupt.txt\"), own_corrupt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34e0ae27-ab72-4572-8654-b034f12744ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined benchmark from neuspell benchmarks\n",
    "neuspell_correct, neuspell_corrupt, neuspell_lowercase = generate_combined_benchmark(neuspell_benchmarks, 200)\n",
    "print(len(neuspell_correct))\n",
    "utils.save_text_file(os.path.join(BENCHMARK_DIR, \"test\", \"sec\", \"spelling_correction\", \"neuspell\", \"correct.txt\"), neuspell_correct)\n",
    "utils.save_text_file(os.path.join(BENCHMARK_DIR, \"test\", \"sec\", \"spelling_correction\", \"neuspell\", \"corrupt.txt\"), neuspell_corrupt)\n",
    "utils.save_text_file(os.path.join(BENCHMARK_DIR, \"test\", \"sec\", \"spelling_correction\", \"neuspell\", \"lowercase.txt\"), neuspell_lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f5ba1c5-1d51-45e9-8676-144d386cc8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n"
     ]
    }
   ],
   "source": [
    "# combined benchmark from own benchmarks + neuspell\n",
    "runtime_correct, runtime_corrupt, _ = generate_combined_benchmark(own_benchmarks + neuspell_benchmarks, 200)\n",
    "utils.save_text_file(os.path.join(BENCHMARK_DIR, \"test\", \"runtime.correct.txt\"), runtime_correct)\n",
    "utils.save_text_file(os.path.join(BENCHMARK_DIR, \"test\", \"runtime.corrupt.txt\"), runtime_corrupt)\n",
    "\n",
    "# combined benchmark from own benchmarks + neuspell with whitespace errors\n",
    "cfg = preprocessing.WhitespaceNoiseConfig(no_whitespace_p=0, full_whitespace_p=0, insert_whitespace_p=0.025, delete_whitespace_p=0.1)\n",
    "whitespace_noise = preprocessing.WhitespaceNoise(cfg=cfg, seed=22)\n",
    "\n",
    "runtime_correct, runtime_corrupt, _ = generate_combined_benchmark(own_benchmarks + neuspell_benchmarks, 200)\n",
    "runtime_corrupt, _, _ = whitespace_noise.apply(runtime_corrupt, runtime_corrupt, [{}] * len(runtime_corrupt))\n",
    "utils.save_text_file(os.path.join(BENCHMARK_DIR, \"test\", \"runtime.whitespaces.correct.txt\"), runtime_correct)\n",
    "utils.save_text_file(os.path.join(BENCHMARK_DIR, \"test\", \"runtime.whitespaces.corrupt.txt\"), runtime_corrupt)\n",
    "\n",
    "print(len(runtime_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f56edf8e-a033-405b-85b7-aed8bdd760a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(BENCHMARK_DIR, \"test\", \"sec\", \"whitespace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e31cc6d5-d099-4ef3-9a41-b36c0936609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_misspellings_file = os.path.join(MISSPELLINGS_DIR, \"test_misspellings.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "608517ee-2b16-4180-a624-1360811ae83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_noise_levels = [0.05, 0.2]\n",
    "err_level_names = [\"low\", \"high\"]\n",
    "ws_ins_noise_levels = [0.025, 0.1]\n",
    "ws_del_noise_levels = [0.1, 0.4]\n",
    "ws_level_names = [\"low\", \"high\"]\n",
    "for i, (err_noise, err_level_name) in enumerate(zip(err_noise_levels, err_level_names)):\n",
    "    cfg = preprocessing.MixedNoiseConfig(\n",
    "        edit_token_p=err_noise, artificial_p=0.5, artificial_num_edits_p=0.8, re_weight_edit_token_p=True, word_misspellings_file=word_misspellings_file\n",
    "    )\n",
    "    error_noise = preprocessing.MixedNoise(cfg=cfg, seed=22 + i)\n",
    "    \n",
    "    own_corrupt_noised, _, _ = error_noise.apply(\n",
    "        own_correct,\n",
    "        own_correct,\n",
    "        [{}] * len(own_correct)\n",
    "    )\n",
    "    for j, (ws_ins_noise, ws_del_noise, ws_level_name) in enumerate(zip(ws_ins_noise_levels, ws_del_noise_levels, ws_level_names)):\n",
    "        cfg = preprocessing.WhitespaceNoiseConfig(no_whitespace_p=0, full_whitespace_p=0, insert_whitespace_p=ws_ins_noise, delete_whitespace_p=ws_del_noise)\n",
    "        whitespace_noise = preprocessing.WhitespaceNoise(cfg=cfg, seed=22 + j)\n",
    "\n",
    "        own_corrupt_noised, _, _ = whitespace_noise.apply(\n",
    "            own_corrupt_noised,\n",
    "            own_corrupt_noised,\n",
    "            [{}] * len(own_corrupt_noised)\n",
    "        )\n",
    "        level_name = f\"{err_level_name}-{ws_level_name}\"\n",
    "        corrupt_output_file = os.path.join(output_dir, level_name, \"corrupt.txt\")\n",
    "        correct_output_file = os.path.join(output_dir, level_name, \"correct.txt\")\n",
    "\n",
    "        utils.save_text_file(corrupt_output_file, own_corrupt_noised)\n",
    "        utils.save_text_file(correct_output_file, own_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0775e18c-a77d-4205-a550-3c0d3d566c33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
