type: MODEL_FOR_TOKENIZATION_REPAIR_PLUS

embedding: ${from_file:embedding/token_embedding.yaml}
max_length: 514

hidden_dim: ${oc.env:NSC_HIDDEN_DIM,512}
dropout: 0.1

input_type: "char"
output_type: "tokenization_repair_plus_sed"

num_tokenization_repair_layers: ${oc.env:NSC_NUM_INPUT_LAYERS,6}
num_word_layers: ${oc.env:NSC_NUM_WORD_LAYERS,6}

start_from_tokenization_repair_checkpoint: ${oc.env:NSC_START_FROM_TOKENIZATION_REPAIR_CHECKPOINT}
fix_tokenization_repair: ${oc.env:NSC_FIX_TOKENIZATION_REPAIR,true}
tokenization_repair_norm: false
num_tokenization_repair_clf_layers: 1
tokenization_repair_feed_forward_dim: 2048
tokenization_repair_activation: gelu
 # use a learned weighted average of the last three tr layers as char representations
tokenization_repair_feature_layers: [-1, -2, -3]
