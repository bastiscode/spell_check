data:
  - ${oc.env:NSC_DATA_DIR}/cleaned/bookcorpus_paragraphs/train_files.txt

output_dir: ${oc.env:NSC_DATA_DIR}/processed/bookcorpus_paragraphs_tokenization_repair_plus
seed: 22
limit: ${oc.env:NSC_LIMIT,100000000}

max_length: 512
tokenizer:
  type: CHAR
preprocessing: ${from_file:preprocessing/tokenization_repair_plus.yaml}
