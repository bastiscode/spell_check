type: TOKENIZATION_REPAIR_PLUS

data_scheme: "tensor"
tokenization_level: "char"

output_type: "tokenization_repair_plus_sed"
fix_tokenization_repair: ${oc.env:NSC_FIX_TOKENIZATION_REPAIR,false}

add_word_features: ${oc.env:NSC_ADD_WORD_FEATURES,true}
dictionary_file: ${oc.env:NSC_DICTIONARY,${oc.env:NSC_DATA_DIR}/dictionaries/merged_train_100k.txt}
