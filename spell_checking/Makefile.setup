.PHONY: download_data
download_data:
	mkdir -p ../data/downloads

	@echo "Downloading latest Wikidump"
	@echo "(Cannot download Wikidump 2020/10/20 as used in the masters thesis since it is no longer available, using latest instead)"

	if [ ! -f ../data/downloads/enwiki-latest-pages-articles-multistream.xml.bz2 ] ; \
		then \
		wget https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles-multistream.xml.bz2 \
		-P ../data/downloads ; \
	fi;

	mkdir -p ../data/raw/wikidump
	python -m wikiextractor.WikiExtractor ../data/downloads/enwiki-latest-pages-articles-multistream.xml.bz2 \
		-o ../data/raw/wikidump

	@echo "Downloading Bookcorpus"

	if [ ! -f ../data/downloads/books1.tar.gz ] ; \
		then \
		wget https://battle.shawwn.com/sdb/books1/books1.tar.gz -P ../data/downloads ; \
	fi;

	mkdir -p ../data/raw/bookcorpus
	tar -xzvf ../data/downloads/books1.tar.gz -C ../data/raw/bookcorpus

.PHONY: download_misspellings
download_misspellings:
	@echo "Downloading misspellings"
	mkdir -p ../data/misspellings
	mkdir -p ../data/misspellings/birkbeck
	wget https://www.dcs.bbk.ac.uk/~ROGER/missp.dat -O ../data/misspellings/birkbeck/missp.dat
	wget https://www.dcs.bbk.ac.uk/~ROGER/holbrook-missp.dat -O ../data/misspellings/birkbeck/holbrook-missp.dat
	wget https://www.dcs.bbk.ac.uk/~ROGER/aspell.dat -O ../data/misspellings/birkbeck/aspell.dat
	wget https://www.dcs.bbk.ac.uk/~ROGER/wikipedia.dat -O ../data/misspellings/birkbeck/wikipedia.dat

	mkdir -p ../data/misspellings/toefl_spell
	wget https://github.com/EducationalTestingService/TOEFL-Spell/blob/master/Annotations.tsv \
	-O ../data/misspellings/toefl_spell/Annotations.tsv

	wget https://github.com/facebookresearch/moe/raw/master/data/moe_misspellings_train.zip \
	-O ../data/misspellings/moe.zip
	unzip ../data/misspellings/moe.zip -d ../data/misspellings/moe

.PHONY: setup_datasets
setup_datasets:
	python scripts/prepare_wikidump.py --in-dir ../data/raw/wikidump --out-dir ../data/cleaned/wikidump --use-paragraphs
	python scripts/prepare_bookcorpus.py --in-dir ../data/raw/bookcorpus --out-dir ../data/cleaned/bookcorpus --use-paragraphs
	python scripts/prepare_neuspell.py --in-dir ../data/raw/neuspell/traintest --out-dir ../data/cleaned/neuspell

.PHONY: setup_misspellings
setup_misspellings:
	python scripts/process_misspellings.py \
	--misspellings-dir ../data/raw/misspellings \
	--data-dir ../data \
	--dictionary ../data/dictionaries/merged_train_100k.txt \
	--out-dir ../data/misspellings

	python scripts/process_misspellings.py \
	--misspellings-dir ../data/raw/misspellings \
	--data-dir ../data \
	--dictionary ../data/dictionaries/merged_train_100k.txt \
	--out-dir ../data/misspellings_no_neuspell_no_bea \
	--no-neuspell --no-bea

.PHONY: setup_tokenizers
setup_tokenizers:
	@echo "Training tokenizers"
	python ../nsc/scripts/train_tokenizer.py --tokenizer BPE --vocab-size 1000 \
	--in-file ../data/cleaned/wikidump/train_files.txt ../data/cleaned/bookcorpus/train_files.txt \
	--out-file ../data/tokenizers/bpe/wiki_bookcorpus_1k_no_prefix_space.pkl \
	--max-sequences 20000000

	python ../nsc/scripts/train_tokenizer.py --tokenizer BPE --vocab-size 10000 \
	--in-file ../data/cleaned/wikidump/train_files.txt ../data/cleaned/bookcorpus/train_files.txt \
	--out-file ../data/tokenizers/bpe/wiki_bookcorpus_10k_no_prefix_space.pkl \
	--max-sequences 20000000

.PHONY: setup_dictionaries
setup_dictionaries:
	@echo "Creating Wikidump dictionary"
	python ../nsc/scripts/create_dictionary.py --in-file ../data/cleaned/wikidump/train_files.txt \
	--out-file ../data/dictionaries/wikidump_train_100k.txt --top-k 100000 --max-sequences 20000000

	@echo "Creating Bookcorpus dictionary"
	python ../nsc/scripts/create_dictionary.py --in-file ../data/cleaned/bookcorpus/train_files.txt \
	--out-file ../data/dictionaries/bookcorpus_train_100k.txt --top-k 100000 --max-sequences 20000000

	@echo "Creating merged dictionaries"
	python ../nsc/scripts/merge_dictionaries.py \
	--dictionaries ../data/dictionaries/wikidump_train_100k.txt ../data/dictionaries/bookcorpus_train_100k.txt \
	--out-file ../data/dictionaries/merged_train_100k.txt --min-freq 0

.PHONY: setup_data
setup_data: setup_datasets setup_tokenizers setup_dictionaries setup_misspellings
