Task (CLI tool/Python class),Model,Description,Default
"tokenization repair (``nsed``/``SpellingErrorDetector``)","eo large arxiv with errors","Large-sized Transformer model (12 layers) that repairs sequences by predicting repair tokens for each character (ported from https://github.com/ad-freiburg/trt).","X"
"tokenization repair (``nsed``/``SpellingErrorDetector``)","eo medium arxiv with errors","Medium-sized Transformer model (6 layers) that repairs sequences by predicting repair tokens for each character (ported from https://github.com/ad-freiburg/trt)."," "
"tokenization repair (``nsed``/``SpellingErrorDetector``)","eo small arxiv with errors","Small-sized Transformer model (3 layers) that repairs sequences by predicting repair tokens for each character (ported from https://github.com/ad-freiburg/trt)."," "
"sed words (``nsed``/``SpellingErrorDetector``)","gnn+","Attentional Graph Neural Network which processes language graphs with fully connected word nodes, word features and fully connected sub-word cliques. Predicts spelling errors on word level using the word node representations.","X"
"sed words (``nsed``/``SpellingErrorDetector``)","gnn+ neuspell","Attentional Graph Neural Network which processes language graphs with fully connected word nodes, word features and fully connected sub-word cliques. Predicts spelling errors on word level using the word node representations. (pretrained without Neuspell and BEA misspellings, finetuned on Neuspell training data)"," "
"sed words (``nsed``/``SpellingErrorDetector``)","transformer","Regular transformer processing a sequence of sub-word tokens. Predicts spelling errors on word level using the aggregated sub-word representations per word."," "
"sed words (``nsed``/``SpellingErrorDetector``)","transformer neuspell","Regular transformer processing a sequence of sub-word tokens. Predicts spelling errors on word level using the aggregated sub-word representations per word. (pretrained without Neuspell and BEA misspellings, finetuned on Neuspell training data)"," "
"sed words (``nsed``/``SpellingErrorDetector``)","transformer+","Regular transformer processing a sequence of sub-word tokens. Before predicting spelling errors, sub-word representations within a word are aggregated and enriched with word features to obtain word representations. Predicts spelling errors on word level using those word representations."," "
"sed words (``nsed``/``SpellingErrorDetector``)","transformer+ neuspell","Regular transformer processing a sequence of sub-word tokens. Before predicting spelling errors, sub-word representations within a word are aggregated and enriched with word features to obtain word representations. Predicts spelling errors on word level using those word representations. (pretrained without Neuspell and BEA misspellings, finetuned on Neuspell training data)"," "
"sed words (``nsed``/``SpellingErrorDetector``)","gnn","Attentional Graph Neural Network which processes language graphs with fully connected word nodes and fully connected sub-word cliques. Predicts spelling errors on word level using the word node representations."," "
"sed words (``nsed``/``SpellingErrorDetector``)","gnn neuspell","Attentional Graph Neural Network which processes language graphs with fully connected word nodes and fully connected sub-word cliques. Predicts spelling errors on word level using the word node representations. (pretrained without Neuspell and BEA misspellings, finetuned on Neuspell training data)"," "
"sed words (``nsed``/``SpellingErrorDetector``)","tokenization repair+","Transformer based model that detects errors in sequences by first correcting the tokenizationand then detecting spelling errors for each word in the repaired text."," "
"sed words (``nsed``/``SpellingErrorDetector``)","tokenization repair++","Transformer based model that detects errors in sequences by first correcting the tokenizationand then detecting spelling errors for each word in the repaired text. Different from tokenization_repair+ because this model was trained additionally to also correct spelling errors (it is also available in nsec)."," "
"sec (``nsec``/``SpellingErrorCorrector``)","transformer words nmt","Transformer model that corrects sequences by translating each word individually from misspelled to correct.","X"
"sec (``nsec``/``SpellingErrorCorrector``)","transformer words nmt neuspell","Transformer model that corrects sequences by translating each word individually from misspelled to correct. (pretrained without Neuspell and BEA misspellings, finetuned on Neuspell training data)"," "
"sec (``nsec``/``SpellingErrorCorrector``)","tokenization repair++","Transformer based model that corrects sequences by first correcting the tokenization, then detecting spelling errors for each word in the repaired text and then translating every detected misspelled word to its corrected version."," "
"sec (``nsec``/``SpellingErrorCorrector``)","transformer nmt","Transformer model that translates a sequence with spelling errors into a sequence without spelling errors."," "
"sec (``nsec``/``SpellingErrorCorrector``)","transformer nmt neuspell","Transformer model that translates a sequence with spelling errors into a sequence without spelling errors. (pretrained without Neuspell and BEA misspellings, finetuned on Neuspell training data)"," "
"sec (``nsec``/``SpellingErrorCorrector``)","transformer with tokenization repair nmt","Transformer model that translates a sequence with spelling and tokenization errors into a sequence without spelling errors and tokenization errors. Different from transformer_nmt because this model tokenizes into characters and was trained on text with spelling and tokenization errors, whereas transformer_nmt tokenizes into sub-words and was trained only on text with spelling errors."," "
